{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samueldatasci/Modelling_biosystems/blob/main/Assignment_20241212.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO CHECK**<br>\n",
        "* Function dataloader and model_generator calculate max_lag differently; which one is correct?\n",
        "* Carefully check function model_generator and/or try to get an alternative;"
      ],
      "metadata": {
        "id": "SKCC7Qq1VFv9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ti0Dgv-9gCTQ"
      },
      "outputs": [],
      "source": [
        "#number of poles of a system is called the order of the system - https://electronics.stackexchange.com/questions/451128/what-does-dominant-pole-pole-mean-related-to-capacitors-and-filters-or-electroni\n",
        "#TC -> \"This \"impulse response\" is made up of different components, each of which decays with a different time constant. Every pole contributes a different component with a different time constant. The time constant is a measure of how fast a component decays: the bigger the time constant, the slower the component decay\n",
        "#A dominant pole is a pole whose time constant is much \"slower\", i.e. bigger, than all the other time constants of the circuit, therefore the corresponding component is still observable after all the other, faster decaying, components have died off.\n",
        "\n",
        "!pip install slycot\n",
        "!pip install control\n",
        "!pip install pymannkendall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dw1RaPQ-oMC"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import seaborn as sns\n",
        "import io\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pymannkendall as mk\n",
        "import statsmodels.api as sm\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import root_mean_squared_error as rmse\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "import control as ctrl\n",
        "#from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy import signal\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#global vars\n",
        "\n",
        "g_subtract_min = True\n",
        "g_normalize = True\n",
        "\n",
        "\n",
        "g_upload = False\n",
        "\n",
        "g_r2_dictionary = {}\n"
      ],
      "metadata": {
        "id": "whv898YIsl6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdf6GPQ2-kvk"
      },
      "outputs": [],
      "source": [
        "def dataloader(data, na, nb, d):\n",
        "\n",
        "    # Initialize empty arrays for lagged features\n",
        "    y = data['y']\n",
        "    u = data['u']\n",
        "    X = pd.DataFrame()\n",
        "\n",
        "\n",
        "    # Create lagged features for output ('a' parameters)\n",
        "    for i in range(1,na+1):\n",
        "        X['y-{}'.format(i)] = y.shift(i)\n",
        "    # Create lagged features for input ('b' parameters)\n",
        "    for i in range(0,nb):\n",
        "        X['u-{}'.format(i + d)] = u.shift(i + d)\n",
        "\n",
        "\n",
        "    #Only select data after a certain value\n",
        "    max_lag = max(na,nb+d)\n",
        "\n",
        "\n",
        "    X = X.iloc[max_lag:]\n",
        "    # Set the target values\n",
        "    y = y[max_lag:]\n",
        "\n",
        "    X.reset_index(drop=True, inplace=True)\n",
        "    y.reset_index(drop=True, inplace=True)\n",
        "    return X, y\n",
        "\n",
        "\n",
        "\n",
        "## NOT USED\n",
        "def r_2(y, y_hat):  ## NOT USED\n",
        "  rskl = r2_score(y,y_hat) # (y_true, y_pred)\n",
        "  return rskl\n",
        "#   y_mean = np.mean(y)\n",
        "#   y_hat_mean = np.mean(y_hat)\n",
        "#   sst = np.sum((y - y_mean) ** 2)\n",
        "#   #ssr = np.sum((y - y_hat_mean) ** 2)\n",
        "#   ssr = np.sum((y - y_hat) ** 2)\n",
        "#   r_squared = 1 - (ssr / sst)\n",
        "#   #print(\"SSR:\", ssr)\n",
        "#   #print(\"SST:\", sst)\n",
        "#   #print(\"Mean of y:\", y_mean)\n",
        "#   #print(\"Variance of y:\", np.var(y))\n",
        "#   print(f'Mine:{r_squared} Sklearn: {rskl}')\n",
        "#   return r_squared\n",
        "  ## NOT USED\n",
        "\n",
        "\n",
        "\n",
        "def model_metrics(y_real,y_sim,na,nb):\n",
        "        # Calculate r-squared and AIC and RMSE and BIC and FPE\n",
        "        k = na + nb # number of parameters\n",
        "        n = len(y_real)\n",
        "        SSR = np.sum((y_real - y_sim) ** 2)\n",
        "        #Calculate usefull Model evaluation parameters\n",
        "        r_squared = r_2(y_real, y_sim)\n",
        "        aic =  2 * (na + nb) + n * np.log(1 - r_squared) # Evaluates the complexicity of the Model\n",
        "        Rmse = rmse(y_real, y_sim[0:])  #Root Mean Squared Error (Less sensitive to outliers: It is less affected by extreme errors compared to RMSE)\n",
        "        fpe = SSR * (n + k) / (n - k)                  #Final Prediction Error(used for model order selection)(Considers both model fit and complexity) (Asymptotically equivalent to AIC: For large sample sizes, FPE and AIC tend to select the same model)\n",
        "        bic = n * np.log(SSR / n) + k * np.log(n)      #Bayesian Information Criterion (BIC penalizes model complexity more heavily than AIC.)(Consistent: more likely to select the true model when sample is bigger)\n",
        "        # YIC calculation\n",
        "        yic = n * np.log(SSR / n) + k * (np.log(n) + np.log(np.log(n))) #NOT THE SLIDES FORMULA (Gemini)\n",
        "\n",
        "\n",
        "        return r_squared, aic, Rmse, bic, fpe\n",
        "\n",
        "def quadratic_eq( a, b, c):\n",
        "\n",
        "    # calculating discriminant using formula\n",
        "    dis = b * b - 4 * a * c\n",
        "    sqrt_val = math.sqrt(abs(dis))\n",
        "\n",
        "    # checking condition for discriminant\n",
        "    if dis > 0:\n",
        "        #print(\"real and different roots\")\n",
        "        root1 = (-b + sqrt_val)/(2 * a)\n",
        "        root2 = (-b - sqrt_val)/(2 * a)\n",
        "\n",
        "    elif dis == 0:\n",
        "        #print(\"real and same roots\")\n",
        "        roots = -b / (2 * a)\n",
        "        root1 = roots\n",
        "        root2 = roots\n",
        "\n",
        "    # when discriminant is less than 0\n",
        "    else:\n",
        "        #print(\"Complex Roots\")\n",
        "        root1 = - b / (2 * a), + i, sqrt_val / (2 * a)\n",
        "        root2 = - b / (2 * a), - i, sqrt_val / (2 * a)\n",
        "\n",
        "    return root1, root2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUVJF6yx0rKl"
      },
      "outputs": [],
      "source": [
        "def model_generator(data, na, nb, d):\n",
        "\n",
        "  #print(f\"Athlete: {code_name[i]}\")\n",
        "  print('\\nModel with {} a parameters, {} b parameters and {} time delay'.format(na,nb,d))\n",
        "  #load the associated data using dataloader(data, na, nb, d)\n",
        "  X_loader, y_loader = dataloader(data, na,  nb, d)\n",
        "\n",
        "  ##Calculate the a and b parameters      #parameters vector [a0...an, b0...bm].T by the formula inv(X.T dot X) dot X.T dot y\n",
        "  parameters = np.linalg.inv(X_loader.T.dot(X_loader)).dot(X_loader.T).dot(y_loader)\n",
        "  parameters_a = parameters[:na]\n",
        "  parameters_b = parameters[na:]\n",
        "\n",
        "  #Create Transfer Function\n",
        "  TF = ctrl.tf(parameters_b, [1, *[-x for x in parameters_a]]) #.tf(num,den)\n",
        "\n",
        "\n",
        "  ## Simulate values of Y\n",
        "  ysim = np.zeros(len(y_loader)) # the plus one is because the first value is initialized and not simulated\n",
        "  max_lag= max(na,nb+d-1)  # Maximum lag across both endogenous and exogenous variables\n",
        "\n",
        "  #Should I initialize the first values that can be measured?  this way is\n",
        "  #ysim[0]= y_loader.values[0] # initialize the first value -> Predicted resut: [127,0,0,0,131,145]\n",
        "  ysim[:max_lag] = y_loader.values[:max_lag]\n",
        "\n",
        "\n",
        "  for k in range(max_lag, len(X_loader)):\n",
        "  # Add the contribution from autoregressive terms (endogenous variables)\n",
        "    for i_a in range(1,na+1):\n",
        "        #print(\"parameter a: \",i_a)\n",
        "        ysim[k] += parameters_a[i_a-1] * ysim[k - i_a]  # Note: parameters_a starts at index 0\n",
        "\n",
        "  # Add the contribution from exogenous input terms (with delay d)\n",
        "    for j_b in range(nb):\n",
        "        ysim[k] += parameters_b[j_b] * X_loader['u-{}'.format(d+j_b)].iloc[k-j_b]  # Note: parameters_b starts at index 0\n",
        "        #print('u-{}'.format(d+j_b),\"  Parameter B:\",j_b,\"  Delay:\",d)\n",
        "\n",
        "\n",
        "\n",
        "  #Used? Needed?\n",
        "  num = parameters_b # b [b1,b2,b3,...] (exogenous)\n",
        "  den = [1, -parameters_a] #a [1,a2,a3,...] (endogenous)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #Calculate SSG(K) and TC\n",
        "  ##SSG = how much the output of a system changes in response to a change in the input.\n",
        "  SSG = sum(parameters_b)/ (1 - sum(parameters_a)) #a unit change in the input (u) will result in a 1.33 unit change in the output (y)\n",
        "  SSG2 = sum(num)/ (sum(den))   #print(\"SSG:\", SSG,'SSG2:',SSG2)\n",
        "\n",
        "  #Calculate the TC\n",
        "  #TF_poles = ctrl.poles(TF) #ctrl.pole ???\n",
        "  TF_zeros = ctrl.zeros(TF)\n",
        "  TF_DCG = ctrl.dcgain(TF) ## SSG = DCgain ?????\n",
        "  #TF_dominant_pole = min(TF_poles, key=lambda p: abs(p.real))  #The dominant pole is the one with the smallest magnitude real part (closest to the imaginary axis). This pole will largely determine the system’s time constant.\n",
        "\n",
        "  TF_poles = ctrl.poles(TF)\n",
        "  if not np.any(TF_poles):  # Check if TF_poles is empty || .any() -> at least one is not 0 || .all() -> all are not 0\n",
        "      print(\"Warning: No poles found for the system. Skipping dominant pole calculation.\")\n",
        "      TF_dominant_pole = None  # Or assign a default value\n",
        "      TF_TC = None  # Or assign a default value\n",
        "  else:\n",
        "      TF_dominant_pole = min(TF_poles, key=lambda p: abs(p.real))\n",
        "      TF_TC = -1 / TF_dominant_pole.real\n",
        "\n",
        "  TF_TC = -1 / TF_dominant_pole.real #The time constant ( \\tau ) is the negative reciprocal of the real part of the dominant pole.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  print(f'SSG:{SSG}, SSG2:{SSG2}, DCG:{TF_DCG}')\n",
        "  #Check if parameters_a has more than one element to avoid the error\n",
        "  #if len(parameters_a) > 1:\n",
        "  #    poles = 1/parameters_a[0]\n",
        "  #else:\n",
        "  #    poles = 1/parameters_a  # In case parameters_a has only one element\n",
        "  if parameters_a.size > 0:  # Check if parameters_a is not empty\n",
        "    poles = 1/parameters_a[0]\n",
        "  else:\n",
        "    poles = 1\n",
        "  #print(\"parameters a\", parameters_a, \"Poles:\", poles)\n",
        "  poles2 = 1/den[1]\n",
        "  #print(\"parameters a2\", den, \"Poles2:\", poles2)\n",
        "\n",
        "  #Check if poles is an array before calculating dominant_pole\n",
        "  #if isinstance(poles, np.ndarray):\n",
        "  #    dominant_pole = poles[np.argmin(np.abs(poles.imag))] #get the dominant\n",
        "  #else:\n",
        "  #   dominant_pole = poles  # If poles is a scalar, directly assign to dominant_pole\n",
        "  dominant_pole = poles\n",
        "\n",
        "  tau = -1 / np.log(dominant_pole)\n",
        "\n",
        "  print(f\"Tau:{tau}, TF_TC:{TF_TC}\")\n",
        "  #print(\"Time constant:\", tau)\n",
        "  #tau2 = -1 / np.log(poles[np.argmin(np.abs(poles.imag))])\n",
        "  #print(\"Time constant2:\", tau2)\n",
        "\n",
        "\n",
        "  #Models Stability\n",
        "  num = parameters_b # b [b1,b2,b3,...] (exogenous)\n",
        "  den1 =  np.insert(-parameters_a, 0, 1)\n",
        "  den = [1] + (-parameters_a).tolist() #a [1,a2,a3,...] (endogenous)\n",
        "  #TF = ctrl.TransferFunction(num, den)    #define transfer function\n",
        "#  poles, zeroes = ctrl.pzmap(TF, plot=True)  #PLOT CIRCLE AND MODEL (DELETE?CHANGE?)\n",
        "  #add unit circle\n",
        "  #plt.gca().add_patch(plt.Circle((0, 0), radius=1, fill=False, color='gray', linestyle='--'))\n",
        "  #plt.show()\n",
        "  #New Verions (TESTED, but NOT CONFIRMED TO DO THE SAME)\n",
        "  #poles, zeroes = ctrl.pole_zero_map(TF)\n",
        "  #ctrl.pole_zero_plot(TF)         #\n",
        "\n",
        "\n",
        "\n",
        "  ## Model evaluation for each generated model use r_squared and aic def above\n",
        "  r_squared, aic, Rmse, bic, fpe = model_metrics(y_loader,ysim,na,nb)\n",
        "\n",
        "  return y_loader, ysim, parameters_a, parameters_b, SSG, tau, r_squared, aic, Rmse, bic, fpe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5bmNNkoT4mf"
      },
      "source": [
        "# 1º Practical assignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GP_kGO--wRp"
      },
      "outputs": [],
      "source": [
        "#g_upload = True\n",
        "if g_upload:\n",
        "    uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8acIURr-wOF"
      },
      "outputs": [],
      "source": [
        "A1M1_df = pd.read_csv('MOB_Dataset1_A1_M1.csv', names=['y','u'])\n",
        "A1M2_df = pd.read_csv('MOB_Dataset1_A1_M2.csv', names=['y','u'])\n",
        "A2M1_df = pd.read_csv('MOB_Dataset1_A2_M3.csv', names=['y','u'])\n",
        "A2M2_df = pd.read_csv('MOB_Dataset1_A2_M4.csv', names=['y','u'])\n",
        "A3M1_df = pd.read_csv('MOB_Dataset1_A3_M5.csv', names=['y','u'])\n",
        "A3M2_df = pd.read_csv('MOB_Dataset1_A3_M6.csv', names=['y','u'])\n",
        "A4M1_df = pd.read_csv('MOB_Dataset1_A4_M7.csv', names=['y','u'])\n",
        "A4M2_df = pd.read_csv('MOB_Dataset1_A4_M8.csv', names=['y','u'])\n",
        "A5M1_df = pd.read_csv('MOB_Dataset1_A5_M9.csv', names=['y','u'])\n",
        "A5M2_df = pd.read_csv('MOB_Dataset1_A5_M10.csv', names=['y','u'])\n",
        "A6M1_df = pd.read_csv('MOB_Dataset1_A6_M11.csv', names=['y','u'])\n",
        "A6M2_df = pd.read_csv('MOB_Dataset1_A6_M12.csv', names=['y','u'])\n",
        "\n",
        "athlete_list = [A1M1_df, A1M2_df, A2M1_df, A2M2_df, A3M1_df, A3M2_df, A4M1_df, A4M2_df, A5M1_df, A5M2_df, A6M1_df, A6M2_df] #12 (6x2)\n",
        "athlete_list_raw = [A1M1_df, A1M2_df, A2M1_df, A2M2_df, A3M1_df, A3M2_df, A4M1_df, A4M2_df, A5M1_df, A5M2_df, A6M1_df, A6M2_df].copy() #12 (6x2)\n",
        "\n",
        "\n",
        "code_name_a1 = ['A1M1', 'A1M2', 'A2M1', 'A2M2', 'A3M1', 'A3M2', 'A4M1', 'A4M2', 'A5M1', 'A5M2', 'A6M1', 'A6M2'] #12"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create lists with different scalers"
      ],
      "metadata": {
        "id": "Hi28_UWWaqpb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create list athlete_list_scaled01 for scaling y and u between 0 and 1"
      ],
      "metadata": {
        "id": "31lMPqX4aYmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# minmaxscl = MinMaxScaler()\n",
        "# athlete_list_scale_d01 = []\n",
        "# for lst in athlete_list:\n",
        "#     lst_scaled = lst.copy()\n",
        "#     lst_scaled['u'] = minmaxscl.fit_transform(lst_scaled[['u']])\n",
        "#     lst_scaled['y'] = minmaxscl.fit_transform(lst_scaled[['y']])\n",
        "#     athlete_list_scale_d01.append( lst_scaled)\n"
      ],
      "metadata": {
        "id": "ktR0cAMlXb5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create list athlete_list_scaled_11 for scaling y and u between -1 and 1"
      ],
      "metadata": {
        "id": "UZHlXjL1ad0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# minmaxscl = MinMaxScaler((-1,1))\n",
        "# athlete_list_scaled_11 = []\n",
        "# for lst in athlete_list:\n",
        "#     lst_scaled = lst.copy()\n",
        "#     lst_scaled['u'] = minmaxscl.fit_transform(lst_scaled[['u']])\n",
        "#     lst_scaled['y'] = minmaxscl.fit_transform(lst_scaled[['y']])\n",
        "#     athlete_list_scaled_11.append( lst_scaled)\n",
        "\n",
        "# # for i in range( len(athlete_list_scaled_11)):\n",
        "# #     lst = athlete_list_scaled_11[i]\n",
        "# #     print(f'#{i} - {code_name_a1[i]}: shape {lst.shape}, U:[{lst[\"u\"].min()}, {lst[\"u\"].max()}], y:[{lst[\"y\"].min()}, {lst[\"y\"].max()}]')\n"
      ],
      "metadata": {
        "id": "sNMw95pAaC-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create list athlete_list_scaled_std for standard scaling of y and u"
      ],
      "metadata": {
        "id": "SeUVk1Lnax0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# standardscl = StandardScaler()\n",
        "# athlete_list_scale_std = []\n",
        "# for lst in athlete_list:\n",
        "#     lst_scaled = lst.copy()\n",
        "#     lst_scaled['u'] = standardscl.fit_transform(lst_scaled[['u']])\n",
        "#     lst_scaled['y'] = standardscl.fit_transform(lst_scaled[['y']])\n",
        "#     athlete_list_scale_std.append( lst_scaled)\n",
        "\n",
        "# # for i in range( len(athlete_list_scale_std)):\n",
        "# #     lst = athlete_list_scale_std[i]\n",
        "# #     print(f'#{i} - {code_name_a1[i]}: shape {lst.shape}, U:[{lst[\"u\"].min()}, {lst[\"u\"].max()}], y:[{lst[\"y\"].min()}, {lst[\"y\"].max()}]')\n"
      ],
      "metadata": {
        "id": "q7dn5Ro8ayXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create list athlete_list_scaled_robust for Robust scaling of y and u"
      ],
      "metadata": {
        "id": "1j1Joiijbety"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# robustscl = RobustScaler()\n",
        "# athlete_list_scale_robust = []\n",
        "# for lst in athlete_list:\n",
        "#     lst_scaled = lst.copy()\n",
        "#     lst_scaled['u'] = robustscl.fit_transform(lst_scaled[['u']])\n",
        "#     lst_scaled['y'] = robustscl.fit_transform(lst_scaled[['y']])\n",
        "#     athlete_list_scale_robust.append( lst_scaled)\n",
        "\n",
        "# # for i in range( len(athlete_list_scale_robust)):\n",
        "# #     lst = athlete_list_scale_robust[i]\n",
        "# #     print(f'#{i} - {code_name_a1[i]}: shape {lst.shape}, U:[{lst[\"u\"].min()}, {lst[\"u\"].max()}], y:[{lst[\"y\"].min()}, {lst[\"y\"].max()}]')\n"
      ],
      "metadata": {
        "id": "_JK3lF2gbjhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create list athlete_list_subtr_min where all numbers are subtracted of the minimum value\n"
      ],
      "metadata": {
        "id": "utxUqRe6cA38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# athlete_list_scale_subtr_min = []\n",
        "# for lst in athlete_list:\n",
        "#     lst_scaled = lst.copy()\n",
        "#     minvals = lst_scaled.min()\n",
        "#     lst_scaled = lst_scaled - minvals\n",
        "#     athlete_list_scale_subtr_min.append( lst_scaled)\n"
      ],
      "metadata": {
        "id": "ShRX8NlDccbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create list athlete_list_subtr_first where all numbers are subtracted of the first value"
      ],
      "metadata": {
        "id": "0YHtnO-mcBf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# athlete_list_scale_subtr_first = []\n",
        "# for lst in athlete_list:\n",
        "#     lst_scaled = lst.copy()\n",
        "#     firstvals = [lst[\"y\"][0], lst[\"u\"][0]]\n",
        "#     lst_scaled = lst_scaled - firstvals\n",
        "#     athlete_list_scale_subtr_first.append( lst_scaled)\n"
      ],
      "metadata": {
        "id": "ed4HL8jQdEeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate moving average"
      ],
      "metadata": {
        "id": "roL5VIiTeOQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mov_avg_wind = 3\n",
        "# athlete_list_mov_wind_5 = []\n",
        "# for lst in athlete_list:\n",
        "#     lst_scaled = lst.copy()\n",
        "#     lst_scaled = lst_scaled.rolling(window=mov_avg_wind, center=True, min_periods=1).mean()\n",
        "#     # lst_scaled[\"u\"] = lst_scaled[\"u\"].rolling(window=mov_avg_wind, center=True, min_periods=1).mean()\n",
        "#     # lst_scaled[\"y\"] = lst_scaled[\"y\"].rolling(window=mov_avg_wind, center=True, min_periods=1).mean()\n",
        "#     athlete_list_mov_wind_5.append( lst_scaled)\n"
      ],
      "metadata": {
        "id": "6-WEFxtGeO8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing:<br>\n",
        "Calculate moving average<br>\n",
        "Then standardize the data\n"
      ],
      "metadata": {
        "id": "_0n2OKkQ3CN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "standardscl = StandardScaler()\n",
        "\n",
        "mov_avg_wind = 3\n",
        "for i in range(len(athlete_list)):\n",
        "    lst = athlete_list[i]\n",
        "    lst_scaled = lst.copy()\n",
        "    lst_scaled = lst_scaled.rolling(window=mov_avg_wind, center=True, min_periods=1).mean()\n",
        "    # lst_scaled[\"u\"] = lst_scaled[\"u\"].rolling(window=mov_avg_wind, center=True, min_periods=1).mean()\n",
        "    # lst_scaled[\"y\"] = lst_scaled[\"y\"].rolling(window=mov_avg_wind, center=True, min_periods=1).mean()\n",
        "\n",
        "    lst_scaled['u'] = standardscl.fit_transform(lst_scaled[['u']])\n",
        "    lst_scaled['y'] = standardscl.fit_transform(lst_scaled[['y']])\n",
        "\n",
        "    athlete_list[i] = lst_scaled\n",
        "\n",
        "\n",
        "# print(athlete_list[0][0:10])\n",
        "# print(athlete_list_raw[0][0:10])\n",
        "\n"
      ],
      "metadata": {
        "id": "v-88vpW83CkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot inputs and outputs, normal and moving average"
      ],
      "metadata": {
        "id": "anzidCJFi-hJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create list athlete_list_scaled_std for standard scaling of y and u"
      ],
      "metadata": {
        "id": "HpgWg1s_bV6b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dNVPWNUH5rPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iter_min = 2000\n",
        "iter_max = 2500\n",
        "\n",
        "mov_avg_wind = 3\n",
        "\n",
        "\n",
        "for i, athlete in enumerate(athlete_list): # enumerate to get the index and athlete_dataframe\n",
        "#for i, athlete in enumerate(athlete_list_raw): # enumerate to get the index and athlete_dataframe\n",
        "  #Start all values at Zero\n",
        "  print(f\"Athlete:{athlete.shape}\")\n",
        "\n",
        "  #Ploting using two axis with different scales\n",
        "  fig, ax1 = plt.subplots(figsize=(20, 6))\n",
        "  ax1.plot(athlete['u'][iter_min:iter_max], color='blue', label='Input')\n",
        "  ax1.set_xlabel('X-axis Time')\n",
        "  ax1.set_ylabel('U1-axis Input', color='blue')\n",
        "  ax1.tick_params('y', colors='blue')\n",
        "  ax2 = ax1.twinx()\n",
        "  #trend = mk.original_test(athlete['y'])\n",
        "  #ax3.plot(trend, color='green', label='Output')\n",
        "  y_mean = np.mean(athlete['y'])\n",
        "#   print(\"Mean of y:\", y_mean)\n",
        "#   print(\"Variance of y:\", np.var(athlete['y']))\n",
        "  ax2.plot(athlete['y'][iter_min:iter_max], color='red', label='Output')\n",
        "  ax2.set_ylabel('Y2-axis Output', color='red')\n",
        "  ax2.tick_params('y', colors='red')\n",
        "  fig.legend(loc=\"upper right\")\n",
        "  fig.suptitle(f\"Athlete: {code_name_a1[i]}\")\n",
        "  fig.tight_layout()\n",
        "\n",
        "  ################\n",
        "  # SUBTRACT MINIMUM\n",
        "\n",
        "#   if g_normalize_minmax:\n",
        "#     athlete['u'] = (athlete['u'] - athlete['u'].min()) / (athlete['u'].max() - athlete['u'].min())\n",
        "#     athlete['y'] = (athlete['y'] - athlete['y'].min()) / (athlete['y'].max() - athlete['y'].min())\n",
        "\n",
        "#   if g_normalize_stdscal:\n",
        "#     athlete['u'] = (athlete['u'] - athlete['u'].mean()) / athlete['u'].std()\n",
        "#     athlete['y'] = (athlete['y'] - athlete['y'].mean()) / athlete['y'].std()\n",
        "\n",
        "\n",
        "#   mov_avrg_u = athlete['u'][iter_min:iter_max].rolling(window=mov_avg_wind, center=True, min_periods=1).mean()\n",
        "#   mov_avrg_y = athlete['y'][iter_min:iter_max].rolling(window=mov_avg_wind, center=True, min_periods=1).mean()\n",
        "\n",
        "\n",
        "  ax1.tick_params('y', colors='blue')\n",
        "  #ax1.plot(mov_avrg_u, color='green', label='Mov-Mean Input')\n",
        "  ax1.plot(athlete_list[i][[\"u\"]][iter_min:iter_max], color='green', label='Mov-Mean Input')\n",
        "\n",
        "  #ax2.plot(mov_avrg_y, color='orange', label='Mov-Mean Output')\n",
        "  ax1.plot(athlete_list[i][[\"y\"]][iter_min:iter_max], color='orange', label='Mov-Mean Output')\n",
        "\n",
        "  ax2.set_ylabel('Y2-axis Input', color='green')\n",
        "  ax2.tick_params('y', colors='green')\n",
        "\n",
        "model_generator(athlete_list_raw[0], 1, 1, 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "HPkucEWknyYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGJTLvCqovdy"
      },
      "source": [
        "## Pre-Processing && Plot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### I'm using this cell just for tests"
      ],
      "metadata": {
        "id": "McNWqzZxjfPn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0KIvM64Xift"
      },
      "outputs": [],
      "source": [
        "#1ºData Preparation\n",
        "#Pre-processing\n",
        "\n",
        "#High frequency disturbances (too high measurement frequency -> Downsampling)\n",
        "#1ºlow pass filter | 2º Downsampling\n",
        "\n",
        "\n",
        "#Outliers\n",
        "dataset = athlete_list[8]\n",
        "\n",
        "#dataset['u'] = dataset['u'] - np.mean(dataset['u'])\n",
        "#dataset['y'] = dataset['y'] - np.mean(dataset['y'])\n",
        "\n",
        "mov_avrg_u = dataset['u'].rolling(window=mov_avg_wind, center=True, min_periods=1).mean()\n",
        "mov_avrg_y = dataset['y'].rolling(window=mov_avg_wind, center=True, min_periods=1).mean()\n",
        "#result = mk.original_test(data)\n",
        "trend = mk.original_test(dataset['y'])\n",
        "#plot\n",
        "fig, ax1 = plt.subplots(figsize=(20, 6))\n",
        "\n",
        "#ax1.plot(dataset['y'], color='blue', label='Real_Output')\n",
        "#ax1.plot(mov_avrg_y, color='red', label='Mov-Mean-output')\n",
        "ax1.set_xlabel('X-axis Time')\n",
        "ax1.set_ylabel('U1-axis Output', color='blue')\n",
        "ax1.tick_params('y', colors='blue')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(dataset['u'], color='green', label='Input')\n",
        "ax2.plot(mov_avrg_u, color='orange', label='Mov-Mean_Input')\n",
        "\n",
        "ax2.set_ylabel('Y2-axis Input', color='green')\n",
        "ax2.tick_params('y', colors='green')\n",
        "\n",
        "fig.legend(loc=\"upper right\")\n",
        "fig.tight_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### For each athlete/game, plot inputs (u) and outputs (y)"
      ],
      "metadata": {
        "id": "oHNFDNhJjsTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i, athlete in enumerate(athlete_list_raw): # enumerate to get the index and athlete_dataframe\n",
        "  #Start all values at Zero\n",
        "  print(f\"Athlete:{athlete.shape}\")\n",
        "\n",
        "  #Ploting using two axis with different scales\n",
        "  fig, ax1 = plt.subplots(figsize=(20, 6))\n",
        "  ax1.plot(athlete['u'], color='blue', label='Input')\n",
        "  ax1.set_xlabel('X-axis Time')\n",
        "  ax1.set_ylabel('U1-axis Input', color='blue')\n",
        "  ax1.tick_params('y', colors='blue')\n",
        "  ax2 = ax1.twinx()\n",
        "  #trend = mk.original_test(athlete['y'])\n",
        "  #ax3 = ax1.twinx()\n",
        "  #ax3.plot(trend, color='green', label='Output')\n",
        "  y_mean = np.mean(athlete['y'])\n",
        "  print(\"Mean of y:\", y_mean)\n",
        "  print(\"Variance of y:\", np.var(athlete['y']))\n",
        "  ax2.plot(athlete['y'], color='red', label='Output')\n",
        "  ax2.set_ylabel('Y2-axis Output', color='red')\n",
        "  ax2.tick_params('y', colors='red')\n",
        "  fig.legend(loc=\"upper right\")\n",
        "  fig.suptitle(f\"Athlete: {code_name_a1[i]}\")\n",
        "  fig.tight_layout()\n"
      ],
      "metadata": {
        "id": "ytB_sv_SJEOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### For each athlete and game, plot moving average of inputs (u) and outputs (y)"
      ],
      "metadata": {
        "id": "yxAH8bSyj7Zn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dr38Drz-UNVn"
      },
      "outputs": [],
      "source": [
        "#1ºData Preparation\n",
        "#Pre-processing && Ploting\n",
        "limit = 0\n",
        "for i, athlete in enumerate(athlete_list): # enumerate to get the index and athlete_dataframe\n",
        "  #Start all values at Zero\n",
        "  print(f\"Athlete:{athlete.shape}\")\n",
        "  #athlete['u'] = athlete['u'] - athlete['u'][0] #0.38\n",
        "  #athlete['y'] = athlete['y'] - athlete['y'][0]\n",
        "\n",
        "  if g_subtract_min:\n",
        "    athlete['u'] = athlete['u'] - athlete['u'].min() #0.64\n",
        "    athlete['y'] = athlete['y'] - athlete['y'].min()\n",
        "\n",
        "  athlete['u'] = athlete['u'].rolling(window=mov_avg_wind, center=True, min_periods=1).mean()\n",
        "  athlete['y'] = athlete['y'].rolling(window=mov_avg_wind, center=True, min_periods=1).mean()\n",
        "\n",
        "#   athlete['u'] = athlete['u'].rolling(window=2, center=True, min_periods=1).mean()\n",
        "#   athlete['y'] = athlete['y'].rolling(window=2, center=True, min_periods=1).mean()\n",
        "\n",
        "\n",
        "  #Ploting using two axis with different scales\n",
        "  fig, ax1 = plt.subplots(figsize=(20, 6))\n",
        "  ax1.plot(athlete['u'], color='blue', label='Input')\n",
        "  ax1.set_xlabel('X-axis Time')\n",
        "  ax1.set_ylabel('U1-axis Input', color='blue')\n",
        "  ax1.tick_params('y', colors='blue')\n",
        "  ax2 = ax1.twinx()\n",
        "  print(\"athlete['u']\",'Max:',athlete['u'].max(),'Min:',athlete['u'].min())\n",
        "  print(\"athlete['y']\",'Max:',athlete['y'].max(),'Min:',athlete['y'].min())\n",
        "\n",
        "  #trend = mk.original_test(athlete['y'])\n",
        "  #ax3 = ax1.twinx()\n",
        "  #ax3.plot(trend, color='green', label='Output')\n",
        "\n",
        "  '''  if athlete.shape[0] == 7743 and limit == 0:\n",
        "    print(\"tEAWDAWDrue\")\n",
        "    athlete_list[0]['u'] = athlete['u']\n",
        "    athlete_list[0]['y'] = athlete['y']\n",
        "    limit +=+ 1'''\n",
        "  #y_mean = np.mean(athlete['y'])\n",
        "  #print(\"Mean of y:\", y_mean)\n",
        "  #print(\"Variance of y:\", np.var(y))\n",
        "  ax2.plot(athlete['y'], color='red', label='Output')\n",
        "  ax2.set_ylabel('Y2-axis Output', color='red')\n",
        "  ax2.tick_params('y', colors='red')\n",
        "  fig.legend(loc=\"upper right\")\n",
        "  fig.suptitle(f\"Athlete: {code_name_a1[i]}\")\n",
        "  fig.tight_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlOimBKSduws"
      },
      "source": [
        "## 2º System Identification"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test models based on na_max, nb_max and xdelay_max, then store results in results_df dataframe"
      ],
      "metadata": {
        "id": "QoYLQVHmkQxm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKFki8Mp-HaT"
      },
      "outputs": [],
      "source": [
        "from re import X\n",
        "# Find the best model structure (time-invariant modelling)\n",
        "results_df = pd.DataFrame(columns=['Athlete_Code','Model_Index', 'na', 'nb', 'd', 'AIC', 'Rsq','RMSE','BIC','FPE'])\n",
        "selected_models = pd.DataFrame(columns=['Athlete_Code','ParamCount','ParamValues','Metrics'])  #ParamCount[na:nb:d] || ParamValues[na,nb] || Metrics[Rsq, AIC, FPE]\n",
        "\n",
        "# Calculate ARX models to the evaluation data with all possible parameters to find the best fit by checking r-squared and AIC\n",
        "na_max = nb_max = xdelay_max = 2\n",
        "model_count=0\n",
        "\n",
        "##Loop through parameters\n",
        "#Starts 1:1:0 .... 3,3,3               (1,na_max|1,nb_max|xdelay_max) (max=4)\n",
        "#Starts 1:1:0 .... 4,4,4               (1,na_max+1|1,nb_max+1|xdelay_max+1)(max=4)\n",
        "#Starts 0:1:0 .... 3,4,4               (na_max|1,nb_max+1|xdelay_max+1)(max=4)\n",
        "\n",
        "for i in range(len(athlete_list)):\n",
        "  data = athlete_list[i]\n",
        "  model_count=0\n",
        "  print(f\"Athlete: {code_name_a1[i]}\")\n",
        "  for na in range(1,na_max+1):\n",
        "    for nb in range(1,nb_max+1):\n",
        "      for d in range(xdelay_max+1):\n",
        "\n",
        "        print('\\nModel #{} Dataset:{} \\nwith {} a parameters, {} b parameters and {} time delay'.format(model_count,code_name_a1[i],na,nb,d))\n",
        "        #load the associated data using dataloader(data, na, nb, d)\n",
        "        X_loader, y_loader = dataloader(data, na,  nb, d)\n",
        "        #print(\"X_loader:\",X_loader)#print(\"y_loader:\",y_loader)\n",
        "\n",
        "\n",
        "        #Correction to use python## Only when values are equal to zero\n",
        "        if X_loader.empty:#\n",
        "            print(\"Skipping model due to empty X_loader.\")\n",
        "            continue # proceed to next iteration\n",
        "        if y_loader.empty:\n",
        "            print(\"Skipping model due to empty y_loader.\")\n",
        "            continue # proceed to next iteration\n",
        "\n",
        "\n",
        "        ##Calculate the a and b parameters\n",
        "        y_loader, ysim, parameters_a, parameters_b, SSG, tau, r_squared, aic, Rmse, bic, fpe = model_generator(data, na, nb, d)\n",
        "\n",
        "\n",
        "        ## Model evaluation for each generated model use r_squared and aic def above\n",
        "        print(\"its regression yield r squared: {}, Akaike's information criteria: {}\".format(r_squared, aic))\n",
        "\n",
        "\n",
        "\n",
        "        # Save relevant information to the empty lists\n",
        "        new_row = pd.DataFrame({'Athlete_Code': code_name_a1[i],'Model_Index': [model_count], 'na': [na], 'nb': [nb], 'd': [d], 'AIC': [aic], 'Rsq': [r_squared],'RMSE':[Rmse], 'BIC':[bic],'FPE':[fpe], 'Parameters_a':[parameters_a], 'Parameters_b':[parameters_b]})\n",
        "        results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
        "        # Update the model counter\n",
        "        model_count += 1\n",
        "\n",
        "\n",
        "  #Plot for each player/game\n",
        "\n",
        "  fig, ax1 = plt.subplots(figsize=(20, 6))\n",
        "  X_axis = np.arange(len(results_df)) #results_df['Model_Index']\n",
        "\n",
        "  #For R-square Error\n",
        "  ax1.plot(X_axis, results_df['Rsq'], color='blue', label='R-squared')\n",
        "  ax1.set_xlabel('Model Index', fontsize=14)  # Increased font size\n",
        "  ax1.set_ylabel('R-squared', color='blue', fontsize=14)  # Increased font size\n",
        "  ax1.tick_params(axis='y', labelcolor='blue', labelsize=12)  # Increased tick label size\n",
        "\n",
        "  #For AIC\n",
        "  ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "  ax2.plot(X_axis, results_df['AIC'], color='red', label='AIC')\n",
        "  ax2.set_ylabel('AIC', color='red', fontsize=14)  # Increased font size\n",
        "  ax2.tick_params(axis='y', labelcolor='red', labelsize=12)  # Increased tick label size\n",
        "\n",
        "  #For RMSE\n",
        "  ax3 = ax1.twinx()\n",
        "  ax3.plot(X_axis, results_df['RMSE'], color='green', label='RMSE', linestyle='--')\n",
        "  ax3.set_ylabel('RMSE', color='green', fontsize=14)\n",
        "  ax3.tick_params(axis='y', labelcolor='green', labelsize=12)\n",
        "\n",
        "  #For FPE\n",
        "  ax4 = ax1.twinx()\n",
        "  ax4.plot(X_axis, results_df['FPE'], color='purple', label='FPE', linestyle=':')\n",
        "  ax4.set_ylabel('RMSE', color='purple', fontsize=14)\n",
        "  ax4.tick_params(axis='y', labelcolor='purple', labelsize=12)\n",
        "\n",
        "  #For BIC\n",
        "  ax5 = ax4.twinx()\n",
        "  ax5.plot(X_axis, results_df['BIC'], color='orange', label='BIC', linestyle='-.')\n",
        "  ax5.set_ylabel('BIC', color='orange', fontsize=14)\n",
        "  ax5.tick_params(axis='y', labelcolor='orange', labelsize=12)\n",
        "\n",
        "  # General graphic configs\n",
        "  fig.legend(loc=\"upper right\", fontsize=12)  # Add a legend for both plots, increased font size\n",
        "  ax1.grid(True, linestyle='--', alpha=0.7)  # Added grid with dashed lines and transparency\n",
        "  ax2.grid(True, linestyle='--', alpha=0.7)  # Added grid with dashed lines and transparency\n",
        "  plt.title('Model Evaluation Metrics vs. Model Index', fontsize=16)  # Added title with increased font size\n",
        "  plt.tight_layout()  # Adjust layout to prevent overlapping elements\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_loader"
      ],
      "metadata": {
        "id": "2XDn4I9tz1wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tI4LhnP8sTm"
      },
      "outputs": [],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCI_IvLn15aF"
      },
      "outputs": [],
      "source": [
        "#Select Best Models\n",
        "scaler = MinMaxScaler()\n",
        "normalized_metrics = scaler.fit_transform(results_df[['AIC', 'Rsq', 'FPE', 'BIC', 'RMSE']])\n",
        "# Create a new DataFrame with the normalized metrics\n",
        "normalized_df = pd.DataFrame(normalized_metrics, columns=['AIC_norm', 'Rsq_norm', 'FPE_norm', 'BIC_norm', 'RMSE_norm'])\n",
        "selection_df = pd.concat([results_df, normalized_df], axis=1)\n",
        "na_max = nb_max = xdelay_max = 2\n",
        "\n",
        "#best_models_df = pd.DataFrame(columns=['Athlete_Code','ParamCount','ParamValues','Metrics'])  #ParamCount[na:nb:d] || ParamValues[na,nb] || Metrics[Rsq, AIC, FPE]\n",
        "best_models_df = pd.DataFrame()\n",
        "\n",
        "\n",
        "num_models = na_max*nb_max*(xdelay_max+1)\n",
        "cases = len(results_df)/(num_models) #12\n",
        "\n",
        "#LOOP for each case (models)\n",
        "for i in range(int(cases)):\n",
        "  print(\"Case: \",i,\"Start: \",(i*num_models),\"End: \",(i+1)*num_models)\n",
        "  #Select each dataset models data\n",
        "  selected_df = selection_df[(i*num_models):(i+1)*num_models].copy()\n",
        "\n",
        "  #Create a Ranking Selection\n",
        "  selected_df['AIC_rank'] = selected_df['AIC'].rank()\n",
        "  selected_df['BIC_rank'] = selected_df['BIC'].rank()\n",
        "\n",
        "  # Rank by Rsq\n",
        "  selected_df['Rsq_rank'] = selected_df['Rsq'].rank(ascending=False)  # Note: ascending=False for Rsq\n",
        "\n",
        "  # Calculate the combined ranking\n",
        "  selected_df['Ranking'] = selected_df['Rsq_rank'] + selected_df['AIC_rank']#+ selected_df['BIC_rank']\n",
        "\n",
        "  best_df = selected_df.sort_values(by='Ranking', ascending=True).iloc[0]\n",
        "  #new_row = pd.DataFrame({'Athlete_Code':[filter['Athlete_Code'][0]],'ParamCount'[\"{}:{}:{}\".format(filter['na'][0],filter['nb'][0],filter['d'][0])],'ParamValues':[],'Metrics':[filter['Rsq'][0],filter['AIC'][0],filter['FPE'][0]]})\n",
        "\n",
        "  #print(best_df)\n",
        "  #print(selected_df.sort_values(by='Ranking', ascending=True))\n",
        "\n",
        "\n",
        "\n",
        "  new_row = pd.DataFrame({'Athlete_Code': [best_df['Athlete_Code']],\n",
        "                          'na': [best_df['na']],\n",
        "                          'nb': [best_df['nb']],\n",
        "                          'd': [best_df['d']],\n",
        "                          'Ranking': [best_df['Ranking']],\n",
        "                          'AIC_rank': [best_df['AIC_rank']],\n",
        "                          'Rsq_rank': [best_df['Rsq_rank']],\n",
        "                          'BIC_rank': [best_df['BIC_rank']],\n",
        "                          'Rsq': [best_df['Rsq']],\n",
        "                          'AIC': [best_df['AIC']],\n",
        "                          'BIC': [best_df['BIC']],\n",
        "                          'FPE': [best_df['FPE']],\n",
        "                          'Parameters_a':[best_df['Parameters_a']],\n",
        "                          'Parameters_b':[best_df['Parameters_b']]})\n",
        "\n",
        "  best_models_df = pd.concat([best_models_df, new_row], ignore_index=True)\n",
        "\n",
        "  #print(selected_df.sort_values(by='Rsq', ascending=False)[:3])\n",
        "  #print(selected_df.sort_values(by='AIC', ascending=True)[:3])\n",
        "  #print(selected_df.sort_values(by='FPE', ascending=True)[:3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWZZatZL3Hwp"
      },
      "outputs": [],
      "source": [
        "#results_df.sort_values(by='Rsq', ascending=False)\n",
        "\n",
        "best_models_df[\"Rsq\"].mean()"
      ]
    },
    {
      "source": [
        "# from google.colab import sheets\n",
        "# sheet = sheets.InteractiveSheet(df=best_models_df)\n"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "cellView": "form",
        "id": "f-4CtvbuIGda"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wU21U8cZvN6G"
      },
      "outputs": [],
      "source": [
        "#Simulate Best Models\n",
        "r2_total = 0\n",
        "for i in range(len(best_models_df)):\n",
        "  print(f\"Athlete: {code_name_a1[i]}\")\n",
        "  #Define Individual Values\n",
        "  data = athlete_list[i]\n",
        "  number_a = best_models_df['na'].iloc[i]\n",
        "  number_b = best_models_df['nb'].iloc[i]\n",
        "  d = best_models_df['d'].iloc[i]\n",
        "\n",
        "\n",
        "\n",
        "  y_loader, y_auto, parameters_a, parameters_b, SSG, tau, r_squared, aic, Rmse, bic, fpe = model_generator(data, number_a, number_b, d)\n",
        "\n",
        "  #Ploting\n",
        "  plt.figure(figsize=(20, 6))\n",
        "  X_axis = np.arange(0,y_loader.shape[0])\n",
        "  #print(X_axis)\n",
        "\n",
        "  plt.plot(data['y'], label='Real Value (y_loader)', color='blue')\n",
        "  #plt.plot(data['u'], label='Real Input (u_loader)', color='purple', linestyle=':')\n",
        "  # Plot the original data (y)    *AUTOMATIC\n",
        "  plt.plot(X_axis, y_auto, label='Predicted (y_auto)', color='red', linestyle='--')\n",
        "\n",
        "  # Add labels and title\n",
        "  plt.xlabel('Time / Index')\n",
        "  plt.ylabel('Values')\n",
        "  plt.title(f'{code_name_a1[i]}     [{number_a},{number_b},{d}]\\nR-squared: {r_squared:.3f}, AIC: {aic:.1f}')\n",
        "  plt.legend()  # Add a legend\n",
        "  plt.grid(True) # Add grid lines for better readability\n",
        "  # Adjust the y-axis limits if necessary for better visualization\n",
        "  #plt.ylim([50, 200])\n",
        "  plt.show()\n",
        "  print(y_auto[:10])\n",
        "\n",
        "\n",
        "  r2_total += r_squared\n",
        "print(f\"Average Total R^2: {r2_total/12}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2Nigw6Do7zT"
      },
      "source": [
        "## Simulate ONE model for ALL Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhSPsh3EpEox"
      },
      "outputs": [],
      "source": [
        "#Simulation ONE model structure\n",
        "one_4_all = pd.DataFrame(columns=['Athlete_Code', 'na', 'nb', 'd','SSG','TC' ,'AIC', 'Rsq','RMSE','BIC','FPE'])\n",
        "number_a=1\n",
        "number_b=1\n",
        "d=1\n",
        "\n",
        "rsq_sum = 0\n",
        "model_count=0\n",
        "for i in range(len(athlete_list)):\n",
        "  data = athlete_list[i]\n",
        "  print(f\"Athlete: {code_name_a1[i]}\")\n",
        "\n",
        "  #Model Generator\n",
        "  y_loader, y_auto, parameters_a, parameters_b, SSG, tau, r_squared, aic, Rmse, bic, fpe = model_generator(data, number_a, number_b, d)\n",
        "  print(\"regression yield r squared: {}, Akaike's information criteria: {}\".format(r_squared, aic))\n",
        "\n",
        "  #Save Results to \"one_4_all\"\n",
        "  new_row = pd.DataFrame({'Athlete_Code': code_name_a1[i],'SSG':[SSG],'TC':[tau], 'Parameters_a':[parameters_a], 'Parameters_b':[parameters_b], 'na': [number_a], 'nb': [number_b], 'd': [d], 'AIC': [aic], 'Rsq': [r_squared],'RMSE':[Rmse], 'BIC':[bic],'FPE':[fpe]})\n",
        "  one_4_all = pd.concat([one_4_all, new_row], ignore_index=True)\n",
        "\n",
        "\n",
        "  model_count += 1\n",
        "  rsq_sum += r_squared\n",
        "\n",
        "\n",
        "  ##Ploting\n",
        "  #\n",
        "  plt.figure(figsize=(20, 6))\n",
        "  X_axis = np.arange(0,y_loader.shape[0])\n",
        "  print(X_axis)\n",
        "  # Plot the actual values (y_loader)\n",
        "  plt.plot(data['y'], label='Real Value', color='blue')\n",
        "  # plt.plot(data['u'], label='Real Input (u_loader)', color='purple', linestyle=':')\n",
        "  # Plot the original data (y)    *AUTOMATIC\n",
        "  plt.plot(X_axis, y_auto, label='Predicted Value', color='red', linestyle='--')\n",
        "\n",
        "  # Add labels and title\n",
        "  plt.xlabel('Time / Index')\n",
        "  plt.ylabel('Values')\n",
        "  plt.title(f'Comparison: Real VS Prediction\\nR-squared: {r_squared:.3f}, AIC: {aic:.1f}')\n",
        "  plt.legend()  # Add a legend\n",
        "  plt.grid(True) # Add grid lines for better readability\n",
        "  # Adjust the y-axis limits if necessary for better visualization\n",
        "  #plt.ylim([50, 200])\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "print(f\"Average Total R^2 Error: {rsq_sum/12}\")\n",
        "#Do the parameter estimates vary a lot between the subjects or between the volleyball matches?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjntCufGo4QH"
      },
      "outputs": [],
      "source": [
        "one_4_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2kixQp2oFxV"
      },
      "outputs": [],
      "source": [
        "#Do the parameter estimates vary a lot between the subjects or between the volleyball matches?\n",
        "athlete_codes = one_4_all['Athlete_Code'].to_list()\n",
        "\n",
        "#Plot for each player/game\n",
        "fig, ax1 = plt.subplots(figsize=(20, 6))\n",
        "X_axis = athlete_codes #results_df['Model_Index']\n",
        "\n",
        "#plot parameters A\n",
        "ax1.plot(X_axis, one_4_all['Parameters_a'].str[0].tolist(), color='blue', label='A1')\n",
        "ax1.set_xlabel('Athlete Code', fontsize=14)  # Increased font size\n",
        "ax1.set_ylabel('Value', fontsize=14)  # Increased font size\n",
        "ax1.tick_params(axis='y', labelcolor='blue', labelsize=12)  # Increased tick label size\n",
        "\n",
        "#Plot parameters B\n",
        "ax1.plot(X_axis, one_4_all['Parameters_b'].str[0].tolist(), color='red', label='B0')\n",
        "#ax1.plot(X_axis, one_4_all['Parameters_b'].str[1].tolist(), color='orange', label='B1')\n",
        "\n",
        "'''#First param B\n",
        "x2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.plot(X_axis, one_4_all['Param_b'].str[0].tolist(), color='red', label='AIC')\n",
        "#ax2.plot(X_axis, one_4_all['Param_b'].str[1].tolist(), color='red', label='AIC')\n",
        "ax2.set_ylabel('Param_b', color='red', fontsize=14)  # Increased font size\n",
        "ax2.tick_params(axis='y', labelcolor='red', labelsize=12)  # Increased tick label size\n",
        "'''\n",
        "\n",
        "\n",
        "# General graphic configs\n",
        "fig.legend(loc=\"upper right\", fontsize=12)  # Add a legend for both plots, increased font size\n",
        "ax1.grid(True, linestyle='--', alpha=0.7)  # Added grid with dashed lines and transparency\n",
        "ax2.grid(True, linestyle='--', alpha=0.7)  # Added grid with dashed lines and transparency\n",
        "plt.title('Model Parameters for each dataset', fontsize=16)  # Added title with increased font size\n",
        "plt.tight_layout()  # Adjust layout to prevent overlapping elements\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W6heiyfDnbxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AaL_wyvodg1"
      },
      "outputs": [],
      "source": [
        "one_4_all[\"Rsq\"].mean()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Basically the same as the previous chart, but just for parameter b"
      ],
      "metadata": {
        "id": "_6fGS7MJoKY_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZUHZAH9en_P"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Extract the 'b' parameter values and athlete codes\n",
        "b_values = one_4_all['Parameters_b'].to_list()\n",
        "athlete_codes = one_4_all['Athlete_Code'].to_list()\n",
        "\n",
        "num_athletes = len(athlete_codes)\n",
        "num_params = len(b_values[0])  # Assuming all athletes have the same number of 'b' parameters\n",
        "\n",
        "# Create an array to store the parameter values for each position\n",
        "param_positions = [[] for _ in range(num_params)]\n",
        "for athlete_params in b_values:\n",
        "    for i, param_value in enumerate(athlete_params):\n",
        "        param_positions[i].append(param_value)\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
        "\n",
        "for i, position_values in enumerate(param_positions):\n",
        "    plt.plot(athlete_codes, position_values, label=f\"Position {i}\")\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel(\"Athlete Code\")\n",
        "plt.ylabel(\"Parameter Value\")\n",
        "plt.title(\"B parameter comparison by position\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egiO4OcxjhNj"
      },
      "outputs": [],
      "source": [
        "best_models_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5wE-SJuv5Gv"
      },
      "outputs": [],
      "source": [
        "one_4_all"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store best_models_df and one_for_all in the dictionary with R2 results\n",
        "\n",
        "g_r2_dictionary[\"INVAR_BestModels\"] = best_models_df[[\"Athlete_Code\", \"na\", \"nb\", \"d\", \"Rsq\"]]\n",
        "g_r2_dictionary[\"INVAR_OneForAll\"] = one_4_all[[\"Athlete_Code\", \"na\", \"nb\", \"d\", \"Rsq\"]]\n"
      ],
      "metadata": {
        "id": "zF8-fB_HeQtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WygaGFPwuAXb"
      },
      "outputs": [],
      "source": [
        "# Biological interpretation\n",
        "\n",
        "#First Order Model\n",
        "## has 1 a-parameters\n",
        "#  Code Here\n",
        "##\n",
        "\n",
        "\n",
        "#Second Order Model\n",
        "## has 2 a-parameters\n",
        "#  Code Here\n",
        "##\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Athlete Average Moder   (???)\n",
        "#structure: 1:2:0\n",
        "#for p_case in best_models_df.iterrows():\n",
        "counter = 0\n",
        "number_a=1\n",
        "number_b=2\n",
        "d=0\n",
        "athlete_mean_model = pd.DataFrame(columns=['Athlete', 'Parameters_a', 'Parameters_b', 'Rsq_M1', 'AIC_M1', 'Rsq_M2', 'AIC_M2'])\n",
        "\n",
        "for pcase in one_4_all.iterrows():\n",
        "  #print(pcase)\n",
        "\n",
        "  if pcase[1][\"Athlete_Code\"][3] == '1':    #First Game\n",
        "    params_a_memory = pcase[1]['Parameters_a']\n",
        "    params_b_memory = pcase[1]['Parameters_b']\n",
        "    counter += 1\n",
        "\n",
        "  else: #second game\n",
        "    mean_a = (params_a_memory + pcase[1]['Parameters_a']) / 2\n",
        "    mean_b = (params_b_memory + pcase[1]['Parameters_b']) / 2\n",
        "\n",
        "    #Simulation\n",
        "    #Simulation for first Game\n",
        "    y_loader, ysim, parameters_a, parameters_b, SSG, tau, r_squared1, aic1, Rmse1, bic1, fpe1 = model_generator(athlete_list[counter-1], number_a, number_b, d)\n",
        "\n",
        "    ## Simulate values of Y\n",
        "    #Plot Simulation\n",
        "    print(\"Game1:\",r_squared1)\n",
        "    plt.plot(y_loader, label='Real Value (y_loader)', color='blue')\n",
        "    plt.plot(np.arange(len(ysim)), ysim, label='Predicted Mean (ysim)', color='red', linestyle='--')\n",
        "    plt.xlabel('Time / Index')\n",
        "    plt.ylabel('Values')\n",
        "    plt.title('Athlete:{}  Game: 1 '.format(pcase[1]['Athlete_Code'][:2]))\n",
        "    plt.legend()  # Add a legend\n",
        "    plt.grid(True) # Add grid lines for better readability\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "      ##Simulation for Second Game\n",
        "    X_loader, y_loader = dataloader(athlete_list[counter], number_a, number_b, d)\n",
        "    y_loader, ysim, parameters_a, parameters_b, SSG, tau, r_squared2, aic2, Rmse2, bic2, fpe2 = model_generator(athlete_list[counter], number_a, number_b, d)\n",
        "\n",
        "    #Plot Simulation\n",
        "    print(\"Game2:\",r_squared2)\n",
        "    plt.plot(y_loader, label='Real Value (y_loader)', color='green')\n",
        "    plt.plot(np.arange(len(ysim)), ysim, label='Predicted Mean (ysim)', color='orange', linestyle='--')\n",
        "    plt.xlabel('Time / Index')\n",
        "    plt.ylabel('Values')\n",
        "    plt.title('Athlete:{}  Game: 2 '.format(pcase[1]['Athlete_Code'][:2]))\n",
        "    plt.legend()  # Add a legend\n",
        "    plt.grid(True) # Add grid lines for better readability\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    #Save to the Dataframe\n",
        "    new_row = pd.DataFrame({'Athlete': [pcase[1]['Athlete_Code'][:2]],'Parameters_a':[mean_a], 'Parameters_b':[mean_b], 'Rsq_M1':[r_squared1], 'AIC_M1':[aic1], 'Rsq_M2':[r_squared2], 'AIC_M2':[aic2]})\n",
        "    athlete_mean_model = pd.concat([athlete_mean_model, new_row], ignore_index=True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqXDiqsduAOX"
      },
      "outputs": [],
      "source": [
        "athlete_mean_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vKA71DLMxW_"
      },
      "source": [
        " ## Time-varying dynamics\n",
        "\n",
        "In the lines bellow we consider that the parameter could change in time. This allows the moddels to have different values,depending on the time, allowing the model to better explain/predict the system behavior.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Used to generate synthetic data"
      ],
      "metadata": {
        "id": "aCH07JCp1GgP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxpqXxv8PLg3"
      },
      "outputs": [],
      "source": [
        "# na = 1\n",
        "# nb = 1\n",
        "# d = 1\n",
        "\n",
        "# #INCORPORATE ASSIGNMENT DATA\n",
        "# X_loader, y_loader = dataloader(athlete_list[1], na, nb, d)\n",
        "# N = len(y_loader)\n",
        "# y = y_loader#.values.reshape(-1,1)\n",
        "# u = X_loader['u-{}'.format(d)].values.reshape(-1,1)\n",
        "\n",
        "# N = len(y_loader)\n",
        "# t = np.arange(N)                                        # example for 'time'/points 0-(N-1)\n",
        "# f = 2 * np.pi / 40                                      # f = chosen frequence for square wave\n",
        "\n",
        "\n",
        "# e = np.random.randn(N, 1) * np.sqrt(0.16)               # Noise vector e-N(0,0.16), 'standard normal distribution'is mean 0, standard deviation 1.\n",
        "# a1 = np.ones((N,1)) * -1                                # a1 = constant\n",
        "# a2 = np.ones((N,1)) * 0.25                              # a2 = constant (if you have a2 means it is second order system)\n",
        "# b0 = np.ones((N,1))\n",
        "# b0[200:899] = 2                                         # b0 = variable\n",
        "# # delay = 1\n",
        "\n",
        "\n",
        "# y = np.zeros((N,1))                                     # start with an empty vector for y\n",
        "# for k in range(max(na, nb+d-1), N):\n",
        "#     y[k] = -a1[k] * y[k-1] - a2[k] * y[k-2] + b0[k] * u[k-d] + e[k]  # if we have a2 means it is a second order system.\n",
        "\n",
        "# plt.plot(u)\n",
        "# plt.plot(y)\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Time-variant 1 - Recursive ARX, RLS (Recursive Least Squares) algorithm"
      ],
      "metadata": {
        "id": "5L4K27h4D2OL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3X6UFltuAAD"
      },
      "outputs": [],
      "source": [
        "def fRLS(chart_title = \"Time-variant - Recursive ARX, RLS (Recursive Least Squares) algorithm\", na=2, nb=1, d=1, showCharts=False, showPrints=False):\n",
        "  #Time-variant - recursive ARX\n",
        "\n",
        "    if na != 2 or nb != 1 or d != 1:\n",
        "        raise ValueError(\"Invalid values for 'na', 'nb' or 'd'. 'na' must be 2, 'nb' must be 1 and 'd' must be 1.\")\n",
        "\n",
        "\n",
        "    df2_rsquared = pd.DataFrame(columns=['Athlete_Code', 'na', 'nb', 'd','Rsq'])\n",
        "\n",
        "    r2_total = 0\n",
        "\n",
        "    for i in range(len(athlete_list)):\n",
        "        data = athlete_list[i]\n",
        "\n",
        "        #INCORPORATE ASSIGNMENT DATA\n",
        "        X_loader, y_loader = dataloader(athlete_list[i], na, nb, d)\n",
        "        N = len(y_loader)\n",
        "\n",
        "        y = y_loader#.values.reshape(-1,1)\n",
        "        u = X_loader['u-{}'.format(d)].values.reshape(-1,1)\n",
        "\n",
        "        #print(\"N:\", N)\n",
        "        #print(\"y:\", y.shape)\n",
        "        #print(\"u:\", u.shape)\n",
        "\n",
        "        t = np.arange(N)                                        # example for 'time'/points 0-(N-1)\n",
        "        f = 2 * np.pi / 40                                      # f = chosen frequence for square wave\n",
        "\n",
        "\n",
        "        #dm  =3                              # Number of parameters to estimate\n",
        "        dm  = na + nb                              # Number of parameters to estimate\n",
        "\n",
        "        # Initialise matrix\n",
        "        X = np.zeros((dm,1))              # prepare an input matrix that can be used in the loop, size is the number of parameters\n",
        "        P = 1000 * np.eye(dm)            # Covariance matrix set to large value because of uncertainty at the beginning due to lack of measurement\n",
        "        a_hat = np.ones((dm,1))         # Minimum value to not create error in case of 0 division\n",
        "\n",
        "\n",
        "        # Information to be stored in the loop\n",
        "        a1est = np.zeros((N,1))\n",
        "        a2est = np.zeros((N,1))\n",
        "        b0est = np.zeros((N,1))\n",
        "\n",
        "\n",
        "        # Loop over all the data\n",
        "        for k in range(max(na, nb+d-1), N):\n",
        "            # 1. Update the matrix X with the new data\n",
        "            X[0] = - y[k-1]\n",
        "            X[1] = - y[k-2]\n",
        "            X[2] = u[k-d]\n",
        "\n",
        "            # 2. Update gain matrix g\n",
        "            g = (P @ X) / (1 +( X.T @ P @ X))\n",
        "\n",
        "            # 3. Update covariance matrix P\n",
        "            P = P - g @ X.T @ P\n",
        "\n",
        "            # 4. Re-estimate the parameter coefficients\n",
        "            yhat =  X.T @ a_hat      # y = data vector * parameters vetor\n",
        "            error = y[k] - yhat\n",
        "            a_hat = a_hat + g * error\n",
        "            # OR: a_hat = a_hat + g * ( y(k) - (X' * a_hat))\n",
        "\n",
        "            # 5. Store estimates (get the diagonal elements of a_hat that correspond to a1, a2, b0)\n",
        "            a1est[k] = a_hat[0]\n",
        "            a2est[k] = a_hat[1]\n",
        "            b0est[k] = a_hat[2]\n",
        "\n",
        "        # Simulate model (step 2)\n",
        "        ysim2 = np.zeros((N,1))\n",
        "        for k in range(max(na, nb+d-1), N):\n",
        "            ysim2[k] = - a1est[k] * ysim2[k-1] - a2est[k] * ysim2[k-2] + b0est[k] * u[k-d]\n",
        "\n",
        "        r_squared = r2_score(y, ysim2)\n",
        "        new_row = pd.DataFrame([[code_name_a1[i], na, nb, d, r_squared]], columns=df2_rsquared.columns)\n",
        "        df2_rsquared = pd.concat([df2_rsquared, new_row], ignore_index=True)\n",
        "\n",
        "        r2_total += r_squared\n",
        "\n",
        "        if showCharts:\n",
        "\n",
        "            plt.title(f\"Param estim - {chart_title}\\nAthlete {code_name_a1[i][:2]}, Game {code_name_a1[i][-1]}\")\n",
        "            plt.plot(a1est, label=\"A1 est\", color=\"blue\")\n",
        "            plt.plot(a2est, label=\"A2 est\", color=\"cyan\")\n",
        "            plt.plot(b0est, label=\"B1 est\", color=\"green\")\n",
        "            plt.xlabel('Time / Index')\n",
        "            plt.ylabel('Values')\n",
        "            plt.legend()\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "            plt.title(f\"Real vs predic, {chart_title}\\nAthlete {code_name_a1[i][:2]}, Game {code_name_a1[i][-1]}. R2: {r2_score(y, ysim2):.3f}\")\n",
        "            plt.plot(y, label=\"y real\", color=\"blue\")\n",
        "            plt.plot(ysim2, label=\"y pred\", color=\"red\")\n",
        "            plt.xlabel('Time / Index')\n",
        "            plt.ylabel('Values')\n",
        "            plt.legend()\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "        if showPrints:\n",
        "\n",
        "            print('R2:',r2_score(y, ysim2))\n",
        "\n",
        "    if showPrints:\n",
        "        print(\"Average R2: {r2_total/12}\")\n",
        "\n",
        "\n",
        "    return df2_rsquared\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfRLS = fRLS(showCharts=False, showPrints=False)\n",
        "g_r2_dictionary[\"RLS\"] = dfRLS\n"
      ],
      "metadata": {
        "id": "CHZf73jkaJej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Time-variant 2 - Recursive ARX RDW - Rectangular Data Weighing"
      ],
      "metadata": {
        "id": "lYeeIoD-EC7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fRDW(win_size = 200, chart_title = \"Time-variant - Recursive ARX RDW (Rectangular Data Weighing) algorithm\", na=2, nb=1, d=1, showCharts=False, showPrints=False):\n",
        "  #Time-variant - recursive ARX\n",
        "\n",
        "  if na != 2 or nb != 1 or d != 1:\n",
        "    raise ValueError(\"Invalid values for 'na', 'nb' or 'd'. 'na' must be 2, 'nb' must be 1 and 'd' must be 1.\")\n",
        "\n",
        "  # Time-variant - recursive ARX\n",
        "\n",
        "  chart_title = f\"{chart_title} (win={win_size})\"\n",
        "  #df = pd.DataFrame(columns=['Athlete_Code', 'na', 'nb', 'd','SSG','TC' ,'AIC', 'Rsq','RMSE','BIC','FPE'])\n",
        "  df3_rsquared = pd.DataFrame(columns=['Athlete_Code', 'na', 'nb', 'd','Rsq'])\n",
        "  r2_total = 0\n",
        "\n",
        "\n",
        "  for i in range(len(athlete_list)):\n",
        "    data = athlete_list[i]\n",
        "\n",
        "    #INCORPORATE ASSIGNMENT DATA\n",
        "    X_loader, y_loader = dataloader(athlete_list[i], na, nb, d)\n",
        "    N = len(y_loader)\n",
        "\n",
        "    y = y_loader#.values.reshape(-1,1)\n",
        "    u = X_loader['u-{}'.format(d)].values.reshape(-1,1)\n",
        "\n",
        "    t = np.arange(N)                                        # example for 'time'/points 0-(N-1)\n",
        "    f = 2 * np.pi / 40                                      # f = chosen frequence for square wave\n",
        "\n",
        "    #dm  =3                              # Number of parameters to estimate\n",
        "    dm  = na + nb                              # Number of parameters to estimate\n",
        "\n",
        "    # Initialise matrix\n",
        "    X = np.zeros((dm,1))              # prepare an input matrix that can be used in the loop, size is the number of parameters\n",
        "    P = 1000 * np.eye(dm)            # Covariance matrix set to large value because of uncertainty at the beginning due to lack of measurement\n",
        "    a_hat = np.ones((dm,1))         # Minimum value to not create error in case of 0 division\n",
        "\n",
        "\n",
        "    # Initialise matrix\n",
        "    X_add = np.zeros((dm,1))\n",
        "    X_remove = np.zeros((dm,1))\n",
        "    P = 1000 * np.eye(dm)             # Covariance matrix set to large value because of uncertainty at the beginning due to lack of measurement\n",
        "    a_hat = np.ones((dm,1))           # Minimum value to don't create error in case of 0 division\n",
        "\n",
        "\n",
        "    # Information to be stored in the loop\n",
        "    a1est = np.zeros((N,1))\n",
        "    a2est = np.zeros((N,1))\n",
        "    b0est = np.zeros((N,1))\n",
        "\n",
        "\n",
        "\n",
        "    for k in range(max(na, nb+d-1), N):\n",
        "        # 1. Update the matrix X with the new data\n",
        "        X_add[0] = -y[k-1]\n",
        "        X_add[1] = -y[k-2]\n",
        "        X_add[2] = u[k-1]\n",
        "\n",
        "        # 2. Update gain matrix\n",
        "        g = P @ X_add / (1 + X_add.T @ P @ X_add)  # inverse of matrix is 'devision'\n",
        "\n",
        "        # 3. Update covariance matrix P\n",
        "        P = P - g @ X_add.T @ P\n",
        "\n",
        "        # 4. Re-estimate the parameter coefficients based on the new data\n",
        "        yhat = X_add.T @ a_hat\n",
        "        error = y[k] - yhat\n",
        "        a_hat = a_hat + g * error\n",
        "\n",
        "        # 5 Remove effect of old data every data at (k-s)th instant\n",
        "        if k - win_size - max(nb + d - 1, na) > 0:\n",
        "            # 5.a Update the matrix X(k-s) with the new data\n",
        "            X_remove[0] = -y[k - win_size - 1] #a1\n",
        "            X_remove[1] = -y[k - win_size - 2] #a2\n",
        "            X_remove[2] = u[k - win_size - d] #b0\n",
        "            # 5.b Update gain matrix\n",
        "            g = -P @ X_remove / (1 + X_remove.T @ P @ X_remove)\n",
        "            # 5.c Update covariance matrix P\n",
        "            P = (P - g @ X_remove.T @ P)\n",
        "            # 5.d Re-estimate the parameter coefficients based on the new data\n",
        "            yhat = X_remove.T @ a_hat\n",
        "            error = y[k - win_size] - yhat\n",
        "            a_hat = a_hat + g * error\n",
        "\n",
        "        a1est[k] = a_hat[0]\n",
        "        a2est[k] = a_hat[1]\n",
        "        b0est[k] = a_hat[2]\n",
        "\n",
        "\n",
        "    # Simulate model (step 3)\n",
        "    ysim3 = np.zeros((N,1))\n",
        "    for k in range(max(na, nb+d-1), N):\n",
        "        ysim3[k] = -a1est[k] * ysim3[k-1] - a2est[k] * ysim3[k-2] + b0est[k] * u[k-d]\n",
        "\n",
        "\n",
        "\n",
        "    r_squared = r2_score(y, ysim3)\n",
        "    #df.append(code_name_a1[i], na, nb, d, SSG, tau, aic, r_squared, Rmse, bic, fpe)\n",
        "    #df.add_row([code_name_a1[i], na, nb, d, SSG, tau, aic, r_squared, Rmse, bic, fpe])\n",
        "    new_row = pd.DataFrame([[code_name_a1[i], na, nb, d, r_squared]], columns=df3_rsquared.columns)\n",
        "    df3_rsquared = pd.concat([df3_rsquared, new_row], ignore_index=True)\n",
        "\n",
        "    r2_total += r_squared\n",
        "\n",
        "\n",
        "    if showCharts:\n",
        "        plt.title(f\"Param estim - {chart_title}\\nAthlete {code_name_a1[i][:2]}, Game {code_name_a1[i][-1]}\")\n",
        "        plt.plot(a1est, label=\"A1 est\", color=\"blue\")\n",
        "        plt.plot(a2est, label=\"A2 est\", color=\"cyan\")\n",
        "        plt.plot(b0est, label=\"B1 est\", color=\"green\")\n",
        "        plt.xlabel('Time / Index')\n",
        "        plt.ylabel('Values')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        #   fig, ax1 = plt.subplots(figsize=(20, 6))\n",
        "        #   fig.suptitle(f\"Athlete: {code_name_a1[i]}\")\n",
        "        #   fig.tight_layout()\n",
        "\n",
        "\n",
        "        plt.title(f\"Real vs predic, {chart_title}\\nAthlete {code_name_a1[i][:2]}, Game {code_name_a1[i][-1]}. R2: {r2_score(y, ysim3):.3f}\")\n",
        "        plt.plot(y, label=\"y real\", color=\"blue\")\n",
        "        plt.plot(ysim3, label=\"y pred\", color=\"red\")\n",
        "        plt.xlabel('Time / Index')\n",
        "        plt.ylabel('Values')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "        if showPrints:\n",
        "\n",
        "            print('R2:',r2_score(y, ysim3))\n",
        "            # print('R2:',r_2(y, ysim2))\n",
        "\n",
        "    if showPrints:\n",
        "        print(\"Average R2: {r2_total/12}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  return df3_rsquared\n"
      ],
      "metadata": {
        "id": "GIqZ3J-eEOyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fRDW_121(win_size = 200, chart_title = \"Time-variant - Recursive ARX RDW (Rectangular Data Weighing) algorithm\", na=1, nb=2, d=1, showCharts=False, showPrints=False):\n",
        "  #Time-variant - recursive ARX\n",
        "\n",
        "  if na != 1 or nb != 2 or d != 1:\n",
        "    raise ValueError(\"Invalid values for 'na', 'nb' or 'd'. 'na' must be 1, 'nb' must be 2 and 'd' must be 1.\")\n",
        "\n",
        "  # Time-variant - recursive ARX\n",
        "\n",
        "  chart_title = f\"{chart_title} (win={win_size})\"\n",
        "  #df = pd.DataFrame(columns=['Athlete_Code', 'na', 'nb', 'd','SSG','TC' ,'AIC', 'Rsq','RMSE','BIC','FPE'])\n",
        "  df3_rsquared = pd.DataFrame(columns=['Athlete_Code', 'na', 'nb', 'd','Rsq'])\n",
        "  r2_total = 0\n",
        "\n",
        "\n",
        "  for i in range(len(athlete_list)):\n",
        "    data = athlete_list[i]\n",
        "\n",
        "    #INCORPORATE ASSIGNMENT DATA\n",
        "    X_loader, y_loader = dataloader(athlete_list[i], na, nb, d)\n",
        "    N = len(y_loader)\n",
        "\n",
        "    y = y_loader#.values.reshape(-1,1)\n",
        "    u = X_loader['u-{}'.format(d)].values.reshape(-1,1)\n",
        "\n",
        "    t = np.arange(N)                                        # example for 'time'/points 0-(N-1)\n",
        "    f = 2 * np.pi / 40                                      # f = chosen frequence for square wave\n",
        "\n",
        "    #dm  =3                              # Number of parameters to estimate\n",
        "    dm  = na + nb                              # Number of parameters to estimate\n",
        "\n",
        "    # Initialise matrix\n",
        "    X = np.zeros((dm,1))              # prepare an input matrix that can be used in the loop, size is the number of parameters\n",
        "    P = 1000 * np.eye(dm)            # Covariance matrix set to large value because of uncertainty at the beginning due to lack of measurement\n",
        "    a_hat = np.ones((dm,1))         # Minimum value to not create error in case of 0 division\n",
        "\n",
        "\n",
        "    # Initialise matrix\n",
        "    X_add = np.zeros((dm,1))\n",
        "    X_remove = np.zeros((dm,1))\n",
        "    P = 1000 * np.eye(dm)             # Covariance matrix set to large value because of uncertainty at the beginning due to lack of measurement\n",
        "    a_hat = np.ones((dm,1))           # Minimum value to don't create error in case of 0 division\n",
        "\n",
        "\n",
        "    # Information to be stored in the loop\n",
        "    a1est = np.zeros((N,1))\n",
        "    b0est = np.zeros((N,1))\n",
        "    b1est = np.zeros((N,1))\n",
        "\n",
        "\n",
        "\n",
        "    for k in range(max(na, nb+d-1), N):\n",
        "        # 1. Update the matrix X with the new data\n",
        "        # X_add[0] = -y[k-1]\n",
        "        # X_add[1] = u[k-1]\n",
        "        # X_add[2] = u[k-2]\n",
        "        X_add[0] = -y[k-1]\n",
        "        X_add[1] = u[k-1]\n",
        "        X_add[2] = u[k-2]\n",
        "\n",
        "        # 2. Update gain matrix\n",
        "        g = P @ X_add / (1 + X_add.T @ P @ X_add)  # inverse of matrix is 'devision'\n",
        "\n",
        "        # 3. Update covariance matrix P\n",
        "        P = P - g @ X_add.T @ P\n",
        "\n",
        "        # 4. Re-estimate the parameter coefficients based on the new data\n",
        "        yhat = X_add.T @ a_hat\n",
        "        error = y[k] - yhat\n",
        "        a_hat = a_hat + g * error\n",
        "\n",
        "        # 5 Remove effect of old data every data at (k-s)th instant\n",
        "        if k - win_size - max(nb + d - 1, na) > 0:\n",
        "            # 5.a Update the matrix X(k-s) with the new data\n",
        "            X_remove[0] = -y[k - win_size - 1] #a1\n",
        "            X_remove[1] = -y[k - win_size - 2] #a2\n",
        "            X_remove[2] = u[k - win_size - d] #b0\n",
        "            # 5.b Update gain matrix\n",
        "            g = -P @ X_remove / (1 + X_remove.T @ P @ X_remove)\n",
        "            # 5.c Update covariance matrix P\n",
        "            P = (P - g @ X_remove.T @ P)\n",
        "            # 5.d Re-estimate the parameter coefficients based on the new data\n",
        "            yhat = X_remove.T @ a_hat\n",
        "            error = y[k - win_size] - yhat\n",
        "            a_hat = a_hat + g * error\n",
        "\n",
        "        a1est[k] = a_hat[0]\n",
        "        b0est[k] = a_hat[1]\n",
        "        b1est[k] = a_hat[2]\n",
        "\n",
        "\n",
        "    # Simulate model (step 3)\n",
        "    ysim3 = np.zeros((N,1))\n",
        "    for k in range(max(na, nb+d-1), N):\n",
        "        ysim3[k] = -a1est[k] * ysim3[k-1] + b0est[k] * u[k-d-1] + b1est[k] * u[k-d]\n",
        "\n",
        "\n",
        "\n",
        "    r_squared = r2_score(y, ysim3)\n",
        "    #df.append(code_name_a1[i], na, nb, d, SSG, tau, aic, r_squared, Rmse, bic, fpe)\n",
        "    #df.add_row([code_name_a1[i], na, nb, d, SSG, tau, aic, r_squared, Rmse, bic, fpe])\n",
        "    new_row = pd.DataFrame([[code_name_a1[i], na, nb, d, r_squared]], columns=df3_rsquared.columns)\n",
        "    df3_rsquared = pd.concat([df3_rsquared, new_row], ignore_index=True)\n",
        "\n",
        "    r2_total += r_squared\n",
        "\n",
        "\n",
        "    if showCharts:\n",
        "        plt.title(f\"Param estim - {chart_title}\\nAthlete {code_name_a1[i][:2]}, Game {code_name_a1[i][-1]}\")\n",
        "        plt.plot(a1est, label=\"A1 est\", color=\"blue\")\n",
        "        plt.plot(b0est, label=\"B0 est\", color=\"cyan\")\n",
        "        plt.plot(b1est, label=\"B1 est\", color=\"green\")\n",
        "        plt.xlabel('Time / Index')\n",
        "        plt.ylabel('Values')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        #   fig, ax1 = plt.subplots(figsize=(20, 6))\n",
        "        #   fig.suptitle(f\"Athlete: {code_name_a1[i]}\")\n",
        "        #   fig.tight_layout()\n",
        "\n",
        "\n",
        "        plt.title(f\"Real vs predic, {chart_title}\\nAthlete {code_name_a1[i][:2]}, Game {code_name_a1[i][-1]}. R2: {r2_score(y, ysim3):.3f}\")\n",
        "        plt.plot(y, label=\"y real\", color=\"blue\")\n",
        "        plt.plot(ysim3, label=\"y pred\", color=\"red\")\n",
        "        plt.xlabel('Time / Index')\n",
        "        plt.ylabel('Values')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "        if showPrints:\n",
        "\n",
        "            print('R2:',r2_score(y, ysim3))\n",
        "            # print('R2:',r_2(y, ysim2))\n",
        "\n",
        "    if showPrints:\n",
        "        print(\"Average R2: {r2_total/12}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  return df3_rsquared\n"
      ],
      "metadata": {
        "id": "PeFzCvvy3KVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for win in [50, 100, 150, 200]:\n",
        "    dfRDW = fRDW_121(win_size = win, showCharts=False, showPrints=False)\n",
        "    g_r2_dictionary[\"RDW121_{}\".format(win)] = dfRDW\n"
      ],
      "metadata": {
        "id": "2L1zVUYdZ5OD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Time-variant 3 - Recursive ARX EWP - Exponential Weighted Past"
      ],
      "metadata": {
        "id": "Hgt5nEZwIpeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fEWP(Alpha = 0.985, chart_title = \"Time-variant - Recursive ARX EWP (Exponential Weighting Past) algorithm\", na=2, nb=1, d=1, showCharts=False, showPrints=False):\n",
        "  #Time-variant - recursive ARX\n",
        "\n",
        "  if na != 2 or nb != 1 or d != 1:\n",
        "    raise ValueError(\"Invalid values for 'na', 'nb' or 'd'. 'na' must be 2, 'nb' must be 1 and 'd' must be 1.\")\n",
        "\n",
        "  # Time-variant - recursive ARX\n",
        "\n",
        "  chart_title = f\"{chart_title} (alpha={Alpha})\"\n",
        "\n",
        "  #Time-variant - recursive ARX with EWP (exponentially weighted past)\n",
        "\n",
        "\n",
        "  df4_rsquared = pd.DataFrame(columns=['Athlete_Code', 'na', 'nb', 'd','Rsq'])\n",
        "  r2_total = 0\n",
        "\n",
        "  for i in range(len(athlete_list)):\n",
        "    data = athlete_list[i]\n",
        "\n",
        "\n",
        "    #INCORPORATE ASSIGNMENT DATA\n",
        "    X_loader, y_loader = dataloader(athlete_list[i], na, nb, d)\n",
        "    N = len(y_loader)\n",
        "\n",
        "    y = y_loader#.values.reshape(-1,1)\n",
        "    u = X_loader['u-{}'.format(d)].values.reshape(-1,1)\n",
        "\n",
        "    t = np.arange(N)                                        # example for 'time'/points 0-(N-1)\n",
        "    f = 2 * np.pi / 40                                      # f = chosen frequence for square wave\n",
        "\n",
        "    #dm  =3                              # Number of parameters to estimate\n",
        "    dm  = na + nb                              # Number of parameters to estimate\n",
        "\n",
        "    # Initialise matrix\n",
        "    X = np.zeros((dm,1))              # prepare an input matrix that can be used in the loop, size is the number of parameters\n",
        "    P = 1000 * np.eye(dm)            # Covariance matrix set to large value because of uncertainty at the beginning due to lack of measurement\n",
        "    a_hat = np.ones((dm,1))         # Minimum value to not create error in case of 0 division\n",
        "\n",
        "\n",
        "    # Information to be stored in the loop\n",
        "    a1est = np.zeros((N,1))\n",
        "    a2est = np.zeros((N,1))\n",
        "    b0est = np.zeros((N,1))\n",
        "\n",
        "\n",
        "    #Loop over all the data\n",
        "    for k in range(max(na, nb+d-1), N):\n",
        "\n",
        "        # 1. Update the matrix X with the new data\n",
        "        X[0] = -y[k-1]\n",
        "        X[1] = -y[k-2]\n",
        "        X[2] = u[k-d]\n",
        "\n",
        "        # 2. Update gain matrix\n",
        "        g = P @ X / (Alpha + X.T @ P @ X)\n",
        "\n",
        "        # 3. Update covariance matrix P\n",
        "        P = (P - g @ X.T @ P) / Alpha\n",
        "\n",
        "        # 4. Re-estimate the parameter coefficients based on the new data\n",
        "        yhat = X.T @ a_hat\n",
        "        error = y[k] - yhat\n",
        "        a_hat = a_hat + g * error\n",
        "\n",
        "        a1est[k] = a_hat[0]\n",
        "        a2est[k] = a_hat[1]\n",
        "        b0est[k] = a_hat[2]\n",
        "\n",
        "\n",
        "    # Simulate model (step 3)\n",
        "    ysim4 = np.zeros((N,1))\n",
        "    for k in range(max(na, nb+d-1), N):\n",
        "        ysim4[k] = -a1est[k] * ysim4[k-1] - a2est[k] * ysim4[k-2] + b0est[k] * u[k-d]\n",
        "\n",
        "\n",
        "\n",
        "    r_squared = r2_score(y, ysim4)\n",
        "    #df.append(code_name_a1[i], na, nb, d, SSG, tau, aic, r_squared, Rmse, bic, fpe)\n",
        "    #df.add_row([code_name_a1[i], na, nb, d, SSG, tau, aic, r_squared, Rmse, bic, fpe])\n",
        "    new_row = pd.DataFrame([[code_name_a1[i], na, nb, d, r_squared]], columns=df4_rsquared.columns)\n",
        "    df4_rsquared = pd.concat([df4_rsquared, new_row], ignore_index=True)\n",
        "\n",
        "    r2_total += r_squared\n",
        "\n",
        "    if showCharts:\n",
        "\n",
        "        plt.title(f\"Param estim - {chart_title}\\nAthlete {code_name_a1[i][:2]}, Game {code_name_a1[i][-1]}\")\n",
        "        plt.plot(a1est, label=\"A1 est\", color=\"blue\")\n",
        "        plt.plot(a2est, label=\"A2 est\", color=\"cyan\")\n",
        "        plt.plot(b0est, label=\"B1 est\", color=\"green\")\n",
        "        plt.xlabel('Time / Index')\n",
        "        plt.ylabel('Values')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "        plt.title(f\"Real vs predic, {chart_title}\\nAthlete {code_name_a1[i][:2]}, Game {code_name_a1[i][-1]}. R2: {r2_score(y, ysim4):.3f}\")\n",
        "        plt.plot(y, label=\"y real\", color=\"blue\")\n",
        "        plt.plot(ysim4, label=\"y pred\", color=\"red\")\n",
        "        plt.xlabel('Time / Index')\n",
        "        plt.ylabel('Values')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if showPrints:\n",
        "\n",
        "        print('R2:',r2_score(y, ysim4))\n",
        "        # print('R2:',r_2(y, ysim2))\n",
        "\n",
        "  if showPrints:\n",
        "    print(\"Average R2: {r2_total/12}\")\n",
        "\n",
        "\n",
        "\n",
        "  return df4_rsquared\n",
        "\n"
      ],
      "metadata": {
        "id": "FnF00kH5LsXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for alp in [.95, .98, .99, .995, .999]:\n",
        "    dfEWP = fEWP(Alpha = alp, showCharts=False, showPrints=False)\n",
        "    g_r2_dictionary[\"EWP_{}\".format(alp)] = dfEWP\n"
      ],
      "metadata": {
        "id": "Dg4rrd-oZupg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combine results"
      ],
      "metadata": {
        "id": "NhKdvpH5RO5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfcomb = g_r2_dictionary[list(g_r2_dictionary.keys())[0]].drop([\"Rsq\"], axis=1)\n",
        "for key in g_r2_dictionary.keys():\n",
        "    dfcomb[key] = g_r2_dictionary[key][\"Rsq\"]\n",
        "meanrow = {\"Athlete_Code\": \"Mean\", \"na\":\"\", \"nb\":\"\", \"d\":\"\"}\n",
        "for key in g_r2_dictionary.keys():\n",
        "    meanrow[key] = dfcomb[key].mean()\n",
        "\n",
        "\n",
        "dfcomb.loc[len(dfcomb)] = meanrow\n",
        "\n",
        "dfcomb\n"
      ],
      "metadata": {
        "id": "R64aPpYRbsYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9RAszUvRN41j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfcomb"
      ],
      "metadata": {
        "id": "4zhQtnaWI7mH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vOo_LDxgI7fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gawg1bDJbh30"
      },
      "outputs": [],
      "source": [
        "#2ºSystem Identification\n",
        "def calcmodel(data, na, nb, d):\n",
        "    # Load the associated data using dataloader(data, na, nb, d)\n",
        "\n",
        "    X_loader, y_loader = dataloader(data, na, nb, d)\n",
        "\n",
        "\n",
        "    # Estimate the a and b parameters vector [a0...an, b0...bm].T by the formula inv(X.T dot X) dot X.T dot y\n",
        "    params = np.linalg.inv(X_loader.T @ X_loader) @ X_loader.T @ y_loader\n",
        "    #params = np.linalg.solve(X_loader.T, X_loader) @ X_loader.T @ y_loader\n",
        "    params = params.values\n",
        "\n",
        "\n",
        "    parameters_a = params[:na]\n",
        "    parameters_b = params[na:]\n",
        "\n",
        "\n",
        "    # Optional: Calculate the predicted values of Y via Matrix-Vector multiplication (this is for prediction, not simulation)\n",
        "    Y_pred = np.dot(X_loader, params)\n",
        "\n",
        "\n",
        "    #Calculate a simulation using the predicted parameters use the following structure:\n",
        "    ysim = np.zeros((len(X_loader)+1,1))  # the plus one is because the first value is initialized and not simulated\n",
        "\n",
        "    ysim[0] = y_loader.values[0]    # initialize the first value\n",
        "    max_lag = max(na, nb + d)  # Maximum lag across both endogenous and exogenous variables\n",
        "\n",
        "    for k in range(max_lag, len(X_loader)):\n",
        "        #Add the contribution from autoregressive terms (endogenous variables)\n",
        "        for i_a in range(1, na + 1):\n",
        "            #ysim[k] += parameters_a[i_a - 1] * ysim[k - i_a]\n",
        "            ysim[k] += parameters_a[i_a - 1] * X_loader.iloc[k, i_a]\n",
        "\n",
        "        #Add the contribution from exogenous input ter\\ms (with delay d)\n",
        "        for j_b in range(1, nb + 1):\n",
        "            #ysim[k] += estimation[i_a - 1] * ysim[k - i_a - X_loader['u-{}'.format(d)]]                    #to get the column at delay u-d use this syntax X_loader['u-{}'.format(d)]\n",
        "            ysim[k] += parameters_b[j_b-1] * X_loader['u-{}'.format(d)].iloc[k-j_b]\n",
        "\n",
        "\n",
        "    # Calculate r-squared\n",
        "    y_loader = y_loader.values.reshape(-1,1)\n",
        "    SS_res = np.sum((y_loader - ysim[1:]) ** 2)  # Residual sum of squares\n",
        "    SS_tot = np.sum((y_loader - np.mean(y_loader)) ** 2)  # Total sum of squares\n",
        "    rsq = 1 - (SS_res / SS_tot)\n",
        "    #print(\"ss_red:\",SS_res,\"ss_tot\",SS_tot,\"RSQ:\",rsq)\n",
        "\n",
        "\n",
        "    # Calculate AIC\n",
        "    n = len(y_loader)  # Number of observations\n",
        "    # Number of parameters (including intercept)\n",
        "    aic =  2 * (na + nb) + len(y_loader) * np.log(1 - rsq) # Evaluates the complexicity of the Model\n",
        "\n",
        "\n",
        "    return Y_pred, ysim, params, rsq, aic\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#print(calcmodel(data,0,1,0))\n",
        "#print(calcmodel(data,1,0,0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIv83bHeUDte"
      },
      "source": [
        "# 2º Practical assignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-UZ6lsg-wLO"
      },
      "outputs": [],
      "source": [
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GssVKDX5oD3"
      },
      "outputs": [],
      "source": [
        "M_334_df = pd.DataFrame()\n",
        "M_343_df = pd.DataFrame()\n",
        "WT_df = pd.DataFrame()\n",
        "Unknown_df = pd.DataFrame()\n",
        "\n",
        "''' [ 4X types\n",
        "  [Wild], [Mut1], [Mut2], [unkown]\n",
        "  [C1, C2, C3, C4, C5, C6]# Wildtype\n",
        "  [[y,u](C1), [y,u](C2), [y,u](C3), [y,u], [y,u], [y,u]]\n",
        "  []\n",
        "  []\n",
        "\n",
        "]\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "# Mutant 334\n",
        "for i in range(1,7):\n",
        "  load_input = pd.read_csv('Mutation334_C{}_In.csv'.format(i), names=['u_C{}'.format(i)])\n",
        "  load_output = pd.read_csv('Mutation334_C{}_Out.csv'.format(i), names=['y_C{}'.format(i)])\n",
        "  M_334_df = pd.concat([M_334_df, load_input, load_output], axis=1)\n",
        "\n",
        "# Mutant 343\n",
        "for i in range(1,7):\n",
        "  load_input = pd.read_csv('Mutation343_C{}_In.csv'.format(i), names=['u_C{}'.format(i)])\n",
        "  load_output = pd.read_csv('Mutation343_C{}_Out.csv'.format(i), names=['y_C{}'.format(i)])\n",
        "  M_343_df = pd.concat([M_343_df, load_input, load_output], axis=1)\n",
        "\n",
        "# WildType\n",
        "for i in range(1,7):\n",
        "  load_input = pd.read_csv('WildType_C{}_In.csv'.format(i), names=['u_C{}'.format(i)])\n",
        "  load_output = pd.read_csv('WildType_C{}_Out.csv'.format(i), names=['y_C{}'.format(i)])\n",
        "  WT_df = pd.concat([WT_df, load_input, load_output], axis=1)\n",
        "\n",
        "\n",
        "# WildType\n",
        "for i in range(1,3):\n",
        "  load_input = pd.read_csv('Unknown_C{}_In.csv'.format(i), names=['u_C{}'.format(i)])\n",
        "  load_output = pd.read_csv('Unknown_C{}_Out.csv'.format(i), names=['y_C{}'.format(i)])\n",
        "  Unknown_df = pd.concat([Unknown_df, load_input, load_output], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCANDp6E-wIh"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Mutant 334\n",
        "\n",
        "M334_C1_In_df = pd.read_csv('Mutation334_C1_In.csv', names=['u'])\n",
        "M334_C2_In_df = pd.read_csv('Mutation334_C2_In.csv', names=['u'])\n",
        "M334_C3_In_df = pd.read_csv('Mutation334_C3_In.csv', names=['u'])\n",
        "M334_C4_In_df = pd.read_csv('Mutation334_C4_In.csv', names=['u'])\n",
        "M334_C5_In_df = pd.read_csv('Mutation334_C5_In.csv', names=['u'])\n",
        "M334_C6_In_df = pd.read_csv('Mutation334_C6_In.csv', names=['u'])\n",
        "\n",
        "M334_C1_Out_df = pd.read_csv('Mutation334_C1_Out.csv', names=['y'])\n",
        "M334_C2_Out_df = pd.read_csv('Mutation334_C2_Out.csv', names=['y'])\n",
        "M334_C3_Out_df = pd.read_csv('Mutation334_C3_Out.csv', names=['y'])\n",
        "M334_C4_Out_df = pd.read_csv('Mutation334_C4_Out.csv', names=['y'])\n",
        "M334_C5_Out_df = pd.read_csv('Mutation334_C5_Out.csv', names=['y'])\n",
        "M334_C6_Out_df = pd.read_csv('Mutation334_C6_Out.csv', names=['y'])\n",
        "\n",
        "Mutant_334_list = [M334_C1_In_df,\n",
        "M334_C2_In_df,\n",
        "M334_C3_In_df,\n",
        "M334_C4_In_df,\n",
        "M334_C5_In_df,\n",
        "M334_C6_In_df,\n",
        "M334_C1_Out_df,\n",
        "M334_C2_Out_df,\n",
        "M334_C3_Out_df,\n",
        "M334_C4_Out_df,\n",
        "M334_C5_Out_df,\n",
        "M334_C6_Out_df] #12\n",
        "\n",
        "# Mutant 343\n",
        "\n",
        "M343_C1_In_df = pd.read_csv('Mutation343_C1_In.csv', names=['u'])\n",
        "M343_C2_In_df = pd.read_csv('Mutation343_C2_In.csv', names=['u'])\n",
        "M343_C3_In_df = pd.read_csv('Mutation343_C3_In.csv', names=['u'])\n",
        "M343_C4_In_df = pd.read_csv('Mutation343_C4_In.csv', names=['u'])\n",
        "M343_C5_In_df = pd.read_csv('Mutation343_C5_In.csv', names=['u'])\n",
        "M343_C6_In_df = pd.read_csv('Mutation343_C6_In.csv', names=['u'])\n",
        "\n",
        "M343_C1_Out_df = pd.read_csv('Mutation343_C1_Out.csv', names=['y'])\n",
        "M343_C2_Out_df = pd.read_csv('Mutation343_C2_Out.csv', names=['y'])\n",
        "M343_C3_Out_df = pd.read_csv('Mutation343_C3_Out.csv', names=['y'])\n",
        "M343_C4_Out_df = pd.read_csv('Mutation343_C4_Out.csv', names=['y'])\n",
        "M343_C5_Out_df = pd.read_csv('Mutation343_C5_Out.csv', names=['y'])\n",
        "M343_C6_Out_df = pd.read_csv('Mutation343_C6_Out.csv', names=['y'])\n",
        "\n",
        "Mutant_343_list = [M343_C1_In_df,\n",
        "M343_C2_In_df,\n",
        "M343_C3_In_df,\n",
        "M343_C4_In_df,\n",
        "M343_C5_In_df,\n",
        "M343_C6_In_df,\n",
        "M343_C1_Out_df,\n",
        "M343_C2_Out_df,\n",
        "M343_C3_Out_df,\n",
        "M343_C4_Out_df,\n",
        "M343_C5_Out_df,\n",
        "M343_C6_Out_df] #12\n",
        "\n",
        "# WildType\n",
        "\n",
        "WildType_C1_In_df = pd.read_csv('WildType_C1_In.csv', names=['u'])\n",
        "WildType_C2_In_df = pd.read_csv('WildType_C2_In.csv', names=['u'])\n",
        "WildType_C3_In_df = pd.read_csv('WildType_C3_In.csv', names=['u'])\n",
        "WildType_C4_In_df = pd.read_csv('WildType_C4_In.csv', names=['u'])\n",
        "WildType_C5_In_df = pd.read_csv('WildType_C5_In.csv', names=['u'])\n",
        "WildType_C6_In_df = pd.read_csv('WildType_C6_In.csv', names=['u'])\n",
        "\n",
        "WildType_C1_Out_df = pd.read_csv('WildType_C1_Out.csv', names=['y'])\n",
        "WildType_C2_Out_df = pd.read_csv('WildType_C2_Out.csv', names=['y'])\n",
        "WildType_C3_Out_df = pd.read_csv('WildType_C3_Out.csv', names=['y'])\n",
        "WildType_C4_Out_df = pd.read_csv('WildType_C4_Out.csv', names=['y'])\n",
        "WildType_C5_Out_df = pd.read_csv('WildType_C5_Out.csv', names=['y'])\n",
        "WildType_C6_Out_df = pd.read_csv('WildType_C6_Out.csv', names=['y'])\n",
        "\n",
        "WildType_list = [WildType_C1_In_df,\n",
        "WildType_C2_In_df,\n",
        "WildType_C3_In_df,\n",
        "WildType_C4_In_df,\n",
        "WildType_C5_In_df,\n",
        "WildType_C6_In_df,\n",
        "WildType_C1_Out_df,\n",
        "WildType_C2_Out_df,\n",
        "WildType_C3_Out_df,\n",
        "WildType_C4_Out_df,\n",
        "WildType_C5_Out_df,\n",
        "WildType_C6_Out_df] #12\n",
        "\n",
        "# Unknown\n",
        "\n",
        "Unknown_C1_In_df = pd.read_csv('Unknown_C1_In.csv', names=['u'])\n",
        "Unknown_C2_In_df = pd.read_csv('Unknown_C2_In.csv', names=['u'])\n",
        "\n",
        "Unknown_C1_Out_df = pd.read_csv('Unknown_C1_Out.csv', names=['y'])\n",
        "Unknown_C2_Out_df = pd.read_csv('Unknown_C2_Out.csv', names=['y'])\n",
        "\n",
        "UnknownType_list = [Unknown_C1_In_df,\n",
        "Unknown_C2_In_df,\n",
        "Unknown_C1_Out_df,\n",
        "Unknown_C2_Out_df] #4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9OgW-gt5bcQ"
      },
      "outputs": [],
      "source": [
        "M_343_df[118:125]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO6HLics5xSx"
      },
      "outputs": [],
      "source": [
        "for variation in [M_334_df, M_343_df, WT_df, Unknown_df]:\n",
        "  for i in range(0,len(variation.columns),2):\n",
        "    input = variation.columns[i]\n",
        "    output = variation.columns[i+1]\n",
        "    #print(input, output)\n",
        "    data = pd.concat([variation[input], variation[output]], axis=1)\n",
        "    data2 = variation[[input, output]].copy()\n",
        "    if (data.values == data2.values).all():\n",
        "      continue\n",
        "      #print('Inputs are all the Equal!')\n",
        "\n",
        "data2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRji0kglnE1u"
      },
      "outputs": [],
      "source": [
        "#Note: All inputs(u) are Equal\n",
        "\n",
        "for variation in [M_334_df, M_343_df, WT_df, Unknown_df]:\n",
        "  counter = 1\n",
        "  #input = variation.iloc[119:, 0] # Access column by index using iloc\n",
        "  #plt.plot(input, label='Input'.format(counter))\n",
        "  input = variation.iloc[100:, 0] # Access column by index using iloc\n",
        "  plt.plot(input, label='Input'.format(counter))\n",
        "  for i in range(0,len(variation.columns),2): #0,2,..8,10 (6X)\n",
        "    #variation.iloc[:, i] = variation.iloc[:, i] - variation.iloc[:, i].min()\n",
        "    #variation.iloc[:, i] = variation.iloc[:, i] - variation.iloc[:, i].mean()\n",
        "    #variation.iloc[:, i] = variation.iloc[:, i] / variation.iloc[:, i].std()\n",
        "\n",
        "    output = variation.iloc[119:, i+1] # Access next column for output\n",
        "\n",
        "\n",
        "\n",
        "    plt.plot(output, label='Output C{}'.format(counter))\n",
        "    plt.legend()\n",
        "    counter += 1\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "code_name = [\"M_334\",\"M_343\",\"WT\",\"Unknown\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ns6fypdR2X-C"
      },
      "outputs": [],
      "source": [
        "#1ºData Preparation\n",
        "#Pre-processing && Ploting\n",
        "for lists in [Mutant_334_list,Mutant_343_list,WildType_list,UnknownType_list]:\n",
        "  pds = pd.DataFrame(columns=['Input','Output'])\n",
        "\n",
        "\n",
        "#Remove the first 119 values (0 or 1) for all the datasets and reset the index for 0\n",
        "#all_datasets_df = [df.iloc[120:].reset_index(drop=True) for df in [M_334_df, M_343_df, WT_df, Unknown_df]]\n",
        "\n",
        "#all_datasets_df = [[M_334_df, M_343_df, WT_df, Unknown_df]]    #Original Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eygQVhzOx2q-"
      },
      "outputs": [],
      "source": [
        "#Set values < 0 to eq 0\n",
        "\n",
        "all_datasets_df = [M_334_df, M_343_df, WT_df, Unknown_df]\n",
        "count = 0\n",
        "for variation in all_datasets_df:\n",
        "  for i in range(0,len(variation.columns),2):\n",
        "    input = variation.columns[i]\n",
        "    output = variation.columns[i+1]\n",
        "\n",
        "    for iter in range(len(variation[output])):\n",
        "      value = variation[output][iter]\n",
        "      if value < 0:\n",
        "        #variation.loc[iter, output] = 0\n",
        "        print(all_datasets_df[count][output][iter])\n",
        "  count += 1\n",
        "\n",
        "\n",
        "#all_datasets_df = [df.iloc[100:].reset_index(drop=True) for df in all_datasets_df]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgQvGYPM8E0x"
      },
      "source": [
        "# 2. System identification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1-lbwK--3WC"
      },
      "outputs": [],
      "source": [
        "all_datasets_df = [df.iloc[119:] for df in [M_334_df, M_343_df, WT_df, Unknown_df]]\n",
        "all_datasets_df[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRH1DdCM2X5b"
      },
      "outputs": [],
      "source": [
        "na_max = nb_max = xdelay_max = 5\n",
        "model_count=0\n",
        "\n",
        "all_datasets_df = [M_334_df, M_343_df, WT_df, Unknown_df]\n",
        "final_results_df = pd.DataFrame(columns=['Code_Name','Model_Index','na','nb','d','AIC','Rsq','RMSE','BIC','FPE','Parameters_a','Parameters_b'])\n",
        "r2_sum = 0\n",
        "##Loop through parameters\n",
        "#Starts 1:1:0 .... 4,4,4               (1,na_max+1|1,nb_max+1|xdelay_max+1)(max=4)\n",
        "#Starts 0:1:0 .... 3,4,4               (na_max|1,nb_max+1|xdelay_max+1)(max=4)\n",
        "counter = nm_count = 0\n",
        "for variation in all_datasets_df:\n",
        "  print(\"Running: \",code_name[nm_count])\n",
        "  for i in range(0,len(variation.columns),2):\n",
        "    data = pd.DataFrame(columns=['Input','Output'])\n",
        "    data['u'] = variation[variation.columns[i]]\n",
        "    data['y'] = variation[variation.columns[i+1]]\n",
        "    print(variation.columns[i],variation.columns[i+1])\n",
        "\n",
        "    #input = variation.columns[i]\n",
        "    #output = variation.columns[i+1]\n",
        "    #data = pd.concat([variation[input].rename(\"u\"), variation[output].rename(\"y\")], axis=1)\n",
        "    model_counter = 0\n",
        "\n",
        "    for na in range(1,na_max+1):\n",
        "      for nb in range(1,nb_max+1):\n",
        "        for d in range(xdelay_max+1):\n",
        "          #print(data)\n",
        "          #Calculate Model\n",
        "          y_loader, ysim, parameters_a, parameters_b, SSG, tau, r_squared, aic, Rmse, bic, fpe = model_generator(data, na, nb, d)\n",
        "\n",
        "          #Save Results\n",
        "          new_row = pd.DataFrame({'Code_Name': code_name[nm_count],'Model_Index': [model_counter], 'na': [na], 'nb': [nb], 'd': [d], 'AIC': [aic], 'Rsq': [r_squared],'RMSE':[Rmse], 'BIC':[bic],'FPE':[fpe], 'Parameters_a':[parameters_a], 'Parameters_b':[parameters_b]})\n",
        "          final_results_df = pd.concat([final_results_df, new_row], ignore_index=True)\n",
        "          r2_sum += r_squared\n",
        "\n",
        "          model_counter += 1\n",
        "  nm_count += 1\n",
        "\n",
        "print(\"Average R2:\", r2_sum/(len(all_datasets_df)*na_max*nb_max*xdelay_max))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhMBst-F2X2P"
      },
      "outputs": [],
      "source": [
        "#Plot for each player/game\n",
        "fig, ax1 = plt.subplots(figsize=(20, 6))\n",
        "X_axis = np.arange(len(final_results_df)) #results_df['Model_Index']\n",
        "\n",
        "#For R-square Error\n",
        "ax1.plot(X_axis, final_results_df['Rsq'], color='blue', label='R-squared')\n",
        "ax1.set_xlabel('Model Index', fontsize=14)  # Increased font size\n",
        "ax1.set_ylabel('R-squared', color='blue', fontsize=14)  # Increased font size\n",
        "ax1.tick_params(axis='y', labelcolor='blue', labelsize=12)  # Increased tick label size\n",
        "\n",
        "#For AIC\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "ax2.plot(X_axis, final_results_df['AIC'], color='red', label='AIC')\n",
        "ax2.set_ylabel('AIC', color='red', fontsize=14)  # Increased font size\n",
        "ax2.tick_params(axis='y', labelcolor='red', labelsize=12)  # Increased tick label size\n",
        "\n",
        "#For RMSE\n",
        "ax3 = ax1.twinx()\n",
        "ax3.plot(X_axis, final_results_df['RMSE'], color='green', label='RMSE', linestyle='--')\n",
        "ax3.set_ylabel('RMSE', color='green', fontsize=14)\n",
        "ax3.tick_params(axis='y', labelcolor='green', labelsize=12)\n",
        "\n",
        "#For FPE\n",
        "ax4 = ax1.twinx()\n",
        "ax4.plot(X_axis, final_results_df['FPE'], color='purple', label='FPE', linestyle=':')\n",
        "ax4.set_ylabel('RMSE', color='purple', fontsize=14)\n",
        "ax4.tick_params(axis='y', labelcolor='purple', labelsize=12)\n",
        "\n",
        "#For BIC\n",
        "ax5 = ax4.twinx()\n",
        "ax5.plot(X_axis, final_results_df['BIC'], color='orange', label='BIC', linestyle='-.')\n",
        "ax5.set_ylabel('BIC', color='orange', fontsize=14)\n",
        "ax5.tick_params(axis='y', labelcolor='orange', labelsize=12)\n",
        "\n",
        "# General graphic configs\n",
        "fig.legend(loc=\"upper right\", fontsize=12)  # Add a legend for both plots, increased font size\n",
        "ax1.grid(True, linestyle='--', alpha=0.7)  # Added grid with dashed lines and transparency\n",
        "ax2.grid(True, linestyle='--', alpha=0.7)  # Added grid with dashed lines and transparency\n",
        "plt.title('Model Evaluation Metrics vs. Model Index', fontsize=16)  # Added title with increased font size\n",
        "plt.tight_layout()  # Adjust layout to prevent overlapping elements\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEVjwyxIQ3El"
      },
      "outputs": [],
      "source": [
        "interval = 5*5*6\n",
        "for value in range(int(len(final_results_df)/(interval))): #0..19 (20x)\n",
        "  #Plot for each player/game\n",
        "\n",
        "  selection = final_results_df[(value*interval):(value+1)*interval]\n",
        "\n",
        "  fig, ax1 = plt.subplots(figsize=(20, 6))\n",
        "  X_axis = np.arange(len(selection)) #results_df['Model_Index']\n",
        "\n",
        "  #For R-square Error\n",
        "  ax1.plot(X_axis, selection['Rsq'], color='blue', label='R-squared')\n",
        "  ax1.set_xlabel('Model Index', fontsize=14)  # Increased font size\n",
        "  ax1.set_ylabel('R-squared', color='blue', fontsize=14)  # Increased font size\n",
        "  ax1.tick_params(axis='y', labelcolor='blue', labelsize=12)  # Increased tick label size\n",
        "\n",
        "  #For AIC\n",
        "  ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "  ax2.plot(X_axis, selection['AIC'], color='red', label='AIC')\n",
        "  ax2.set_ylabel('AIC', color='red', fontsize=14)  # Increased font size\n",
        "  ax2.tick_params(axis='y', labelcolor='red', labelsize=12)  # Increased tick label size\n",
        "\n",
        "  #For RMSE\n",
        "  ax3 = ax1.twinx()\n",
        "  ax3.plot(X_axis, selection['RMSE'], color='green', label='RMSE', linestyle='--')\n",
        "  ax3.set_ylabel('RMSE', color='green', fontsize=14)\n",
        "  ax3.tick_params(axis='y', labelcolor='green', labelsize=12)\n",
        "\n",
        "  #For FPE\n",
        "  ax4 = ax1.twinx()\n",
        "  ax4.plot(X_axis, selection['FPE'], color='purple', label='FPE', linestyle=':')\n",
        "  ax4.set_ylabel('RMSE', color='purple', fontsize=14)\n",
        "  ax4.tick_params(axis='y', labelcolor='purple', labelsize=12)\n",
        "\n",
        "  #For BIC\n",
        "  ax5 = ax4.twinx()\n",
        "  ax5.plot(X_axis, selection['BIC'], color='orange', label='BIC', linestyle='-.')\n",
        "  ax5.set_ylabel('BIC', color='orange', fontsize=14)\n",
        "  ax5.tick_params(axis='y', labelcolor='orange', labelsize=12)\n",
        "\n",
        "  # General graphic configs\n",
        "  fig.legend(loc=\"upper right\", fontsize=12)  # Add a legend for both plots, increased font size\n",
        "  ax1.grid(True, linestyle='--', alpha=0.7)  # Added grid with dashed lines and transparency\n",
        "  ax2.grid(True, linestyle='--', alpha=0.7)  # Added grid with dashed lines and transparency\n",
        "  plt.title(f'Model Evaluation Metrics vs. Model Index               Sample:{value}', fontsize=16)  # Added title with increased font size\n",
        "  plt.tight_layout()  # Adjust layout to prevent overlapping elements\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tREVbtvSldX8"
      },
      "outputs": [],
      "source": [
        "final_results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CANtWm72Xyw"
      },
      "outputs": [],
      "source": [
        "final_results_df.sort_values(by='Rsq', ascending=False)[:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDmvhIjK2XvD"
      },
      "outputs": [],
      "source": [
        "#Select Best Models\n",
        "scaler = MinMaxScaler()\n",
        "normalized_metrics = scaler.fit_transform(final_results_df[['AIC', 'Rsq', 'FPE', 'BIC', 'RMSE']])\n",
        "# Create a new DataFrame with the normalized metrics\n",
        "normalized_df = pd.DataFrame(normalized_metrics, columns=['AIC_norm', 'Rsq_norm', 'FPE_norm', 'BIC_norm', 'RMSE_norm'])\n",
        "selection_df = pd.concat([final_results_df, normalized_df], axis=1)\n",
        "\n",
        "\n",
        "best_models_df = pd.DataFrame()\n",
        "\n",
        "\n",
        "num_models = na_max*nb_max*(xdelay_max+1) # 5X5X6\n",
        "cases = len(final_results_df)/(num_models) #3000 / 150 = 20\n",
        "\n",
        "#LOOP for each case (models)\n",
        "for i in range(int(cases)): #0,1..19\n",
        "  print(\"Case: \",i,\"Start: \",(i*num_models),\"End: \",(i+1)*num_models)\n",
        "  #Select each dataset models data\n",
        "  selected_df = selection_df[(i*num_models):(i+1)*num_models].copy()\n",
        "\n",
        "  #Create a Ranking Selection\n",
        "  selected_df['AIC_rank'] = selected_df['AIC'].rank()\n",
        "  selected_df['BIC_rank'] = selected_df['BIC'].rank()\n",
        "\n",
        "  # Rank by Rsq\n",
        "  selected_df['Rsq_rank'] = selected_df['Rsq'].rank(ascending=True)  # Note: ascending=False for Rsq\n",
        "\n",
        "  # Calculate the combined ranking\n",
        "  selected_df['Ranking'] = selected_df['Rsq_rank'] + selected_df['AIC_rank']#+ selected_df['BIC_rank']\n",
        "  best_df = selected_df.sort_values(by='Ranking', ascending=True).iloc[0]\n",
        "\n",
        "  new_row = pd.DataFrame({'Code_Name': [best_df['Code_Name']],\n",
        "                          'na': [best_df['na']],\n",
        "                          'nb': [best_df['nb']],\n",
        "                          'd': [best_df['d']],\n",
        "                          'Ranking': [best_df['Ranking']],\n",
        "                          'AIC_rank': [best_df['AIC_rank']],\n",
        "                          'Rsq_rank': [best_df['Rsq_rank']],\n",
        "                          'BIC_rank': [best_df['BIC_rank']],\n",
        "                          'Rsq': [best_df['Rsq']],\n",
        "                          'AIC': [best_df['AIC']],\n",
        "                          'BIC': [best_df['BIC']],\n",
        "                          'FPE': [best_df['FPE']],\n",
        "                          'Parameters_a':[best_df['Parameters_a']],\n",
        "                          'Parameters_b':[best_df['Parameters_b']]})\n",
        "\n",
        "  #Save new model\n",
        "  best_models_df = pd.concat([best_models_df, new_row], ignore_index=True)\n",
        "\n",
        "  #print(selected_df.sort_values(by='Rsq', ascending=False)[:3])\n",
        "  #print(selected_df.sort_values(by='AIC', ascending=True)[:3])\n",
        "  #print(selected_df.sort_values(by='FPE', ascending=True)[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbxRQgRl2XsM"
      },
      "outputs": [],
      "source": [
        "best_models_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNyZbqH7U5Ba"
      },
      "outputs": [],
      "source": [
        "for x in all_datasets_df:\n",
        "  #print(x.columns[(i)*2:(i*2)+1])\n",
        "  print(x.columns)\n",
        "  for y in range(0,len(x.columns),2):\n",
        "    sample = pd.DataFrame(columns=['y','u'])\n",
        "    sample['y'] = x[x.columns[y]]\n",
        "    sample['u'] = x[x.columns[y+1]]\n",
        "    #print(x.columns[y],x.columns[y+1\n",
        "    print(x.columns[y],x.columns[y+1])\n",
        "    print(y)\n",
        "    y_loader, y_auto, parameters_a, parameters_b, SSG, tau, r_squared, aic, Rmse, bic, fpe = model_generator(sample, 2, 2, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHnF41oHROng"
      },
      "outputs": [],
      "source": [
        "best_models_df#.sort_values(by='Ranking', ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pycBksDAUAWE"
      },
      "outputs": [],
      "source": [
        "#Simulate Best Models\n",
        "r2_total = 0\n",
        "for i in range(len(best_models_df)):\n",
        "  print(f\"Case: {[best_models_df['Code_Name'][i]]}_{i%6}\")\n",
        "  #Define Individual Values\n",
        "  data = all_datasets_df[i]\n",
        "\n",
        "  print(data.columns)\n",
        "  for dataset in range(0,len(data.columns),2):\n",
        "    print(data.columns[dataset],data.columns[dataset+1])\n",
        "\n",
        "\n",
        "    sample = pd.DataFrame(columns=['y','u'])\n",
        "    number_a = best_models_df['na'].iloc[i]\n",
        "    number_b = best_models_df['nb'].iloc[i]\n",
        "    d = best_models_df['d'].iloc[i]\n",
        "    sample['y'] = data[data.columns[dataset+1]]\n",
        "    sample['u'] = data[data.columns[dataset]]\n",
        "\n",
        "    print(dataset)\n",
        "\n",
        "    y_loader, y_auto, parameters_a, parameters_b, SSG, tau, r_squared, aic, Rmse, bic, fpe = model_generator(sample, number_a, number_b, d)\n",
        "    data = sample\n",
        "    #Ploting\n",
        "    plt.figure(figsize=(20, 6))\n",
        "    X_axis = np.arange(0,y_loader.shape[0])\n",
        "    #print(X_axis)\n",
        "\n",
        "    plt.plot(data['y'], label='Real Value (y_loader)', color='blue')\n",
        "    plt.plot(data['u'], label='Real Input (u_loader)', color='purple', linestyle=':')\n",
        "    # Plot the original data (y)    *AUTOMATIC\n",
        "    plt.plot(X_axis, y_auto, label='Predicted Automatic (y_auto)', color='red', linestyle='--')\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.xlabel('Time / Index')\n",
        "    plt.ylabel('Values')\n",
        "    plt.title(f'{code_name[i]}     [{number_a},{number_b},{d}]\\nR-squared: {r_squared:.3f}, AIC: {aic:.1f}')\n",
        "    plt.legend()  # Add a legend\n",
        "    plt.grid(True) # Add grid lines for better readability\n",
        "    # Adjust the y-axis limits if necessary for better visualization\n",
        "    #plt.ylim([50, 200])\n",
        "    plt.show()\n",
        "    print(y_auto[:10])\n",
        "\n",
        "\n",
        "    r2_total += r_squared\n",
        "print(f\"Average Total R^2 Error: {r2_total/12}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yAxSD43i34D"
      },
      "outputs": [],
      "source": [
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf, plot_ccf\n",
        "#Simulation best model structure\n",
        "number_a=3\n",
        "number_b=1\n",
        "d=0\n",
        "lags_v = 250\n",
        "\n",
        "input = [M_334_df, M_343_df, WT_df, Unknown_df][0][['u_C1']].rename(columns={'u_C1': \"u\"}) #Select input column as DataFrame and rename\n",
        "output = [M_334_df, M_343_df, WT_df, Unknown_df][0][['y_C1']].rename(columns={'y_C1': \"y\"}) #Select output column as DataFrame and rename\n",
        "data = pd.concat([input,output], axis=1) #Concatenate along columns (axis=1)\n",
        "\n",
        "\n",
        "# print the relative dataframe and check its columns\n",
        "y_loader, y_auto, parameters_a, parameters_b, SSG, tau, r_squared, aic, Rmse, bic, fpe = model_generator(data, number_a, number_b, d)\n",
        "\n",
        "# Calculate the noise term (residuals)\n",
        "noise = y_loader - y_auto  # Assuming 'y' is the actual output column in your 'data' DataFrame\n",
        "print(noise)\n",
        "# Autocorrelation of the noise\n",
        "fig, ax = plt.subplots(figsize=(12, 4))\n",
        "plot_acf(noise, lags=lags_v, ax=ax)  # Adjust 'lags' as needed\n",
        "plt.title('Autocorrelation of Noise')\n",
        "plt.xlabel('Lag')\n",
        "plt.ylabel('Autocorrelation')\n",
        "plt.show()\n",
        "\n",
        "# Partial Autocorrelation of the noise\n",
        "fig, ax = plt.subplots(figsize=(12, 4))\n",
        "plot_pacf(noise, lags=lags_v, ax=ax)  # Adjust 'lags' as needed\n",
        "plt.title('Partial Autocorrelation of Noise')\n",
        "plt.xlabel('Lag')\n",
        "plt.ylabel('Partial Autocorrelation')\n",
        "plt.show()\n",
        "\n",
        "# Cross-correlation between input (u) and noise\n",
        "fig, ax = plt.subplots(figsize=(12, 4))\n",
        "plot_ccf(data['u'].values, noise, lags=lags_v, ax=ax)  # Adjust 'lags' as needed\n",
        "plt.title('Cross-correlation between Input and Noise')\n",
        "plt.xlabel('Lag')\n",
        "plt.ylabel('Cross-correlation')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Ploting\n",
        "plt.figure(figsize=(20, 6))\n",
        "X_axis = np.arange(0,y_loader.shape[0])\n",
        "print(X_axis)\n",
        "# Plot the actual values (y_loader)\n",
        "plt.plot(data['y'], label='Real Value (y_loader)', color='blue')\n",
        "plt.plot(data['u'], label='Real Input (y_loader)', color='purple', linestyle=':')\n",
        "# Plot the original data (y)    *AUTOMATIC\n",
        "plt.plot(X_axis, y_auto, label='Predicted Automatic (y_auto)', color='red', linestyle='--')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Time / Index')\n",
        "plt.ylabel('Values')\n",
        "plt.title(f'Name:{code_name[0]} Comparison of Real data (y_loader) and Model Prediction (y_auto) - R-squared: {r_squared:.4f}\\nParameter a:{parameters_a} Parameter b:{parameters_b} ')\n",
        "plt.legend()  # Add a legend\n",
        "plt.grid(True) # Add grid lines for better readability\n",
        "# Adjust the y-axis limits if necessary for better visualization\n",
        "#plt.ylim([50, 200])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Fle0H8wiCJf"
      },
      "outputs": [],
      "source": [
        "#Simulation All best model structures\n",
        "number_a = 3\n",
        "number_b = 1\n",
        "d = 0\n",
        "\n",
        "count = 0\n",
        "for dataset in all_datasets_df:\n",
        "  for i in range(0,len(dataset.columns),2):\n",
        "    name_in = dataset.columns[i]\n",
        "    name_out = dataset.columns[i+1]\n",
        "\n",
        "    input = dataset[[name_in]].rename(columns={f'{name_in}': \"u\"}) #Select input column as DataFrame and rename\n",
        "    output = dataset[[name_out]].rename(columns={name_out: \"y\"}) #Select output column as DataFrame and rename\n",
        "    data = pd.concat([input, output], axis=1) #Concatenate along columns (axis=1)\n",
        "\n",
        "\n",
        "    # print the relative dataframe and check its columns\n",
        "    y_loader, y_auto, parameters_a, parameters_b, SSG, tau, r_squared, aic, Rmse, bic, fpe = model_generator(data, number_a, number_b, d)\n",
        "\n",
        "    print(ctrl.TransferFunction(parameters_a,parameters_b))\n",
        "\n",
        "    #Ploting\n",
        "    plt.figure(figsize=(20, 6))\n",
        "    X_axis = np.arange(0,y_loader.shape[0])\n",
        "    # Plot the actual values (y_loader)\n",
        "    plt.plot(data['y'], label='Real Value (y_loader)', color='blue')\n",
        "    plt.plot(data['u'], label='Real Input (y_loader)', color='purple', linestyle=':')\n",
        "    # Plot the original data (y)    *AUTOMATIC\n",
        "    plt.plot(X_axis, y_auto, label='Predicted Automatic (y_auto)', color='red', linestyle='--')\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.xlabel('Time / Index')\n",
        "    plt.ylabel('Values')\n",
        "    plt.title(f'Dataset: {code_name[count]}_{i}       R2: {r_squared:.4f}\\nParameter a:{parameters_a} Parameter b:{parameters_b} ') # Include R-squared in the title\n",
        "    plt.legend()  # Add a legend\n",
        "    plt.grid(True) # Add grid lines for better readability\n",
        "    # Adjust the y-axis limits if necessary for better visualization\n",
        "    #plt.ylim([50, 200])\n",
        "    plt.show()\n",
        "  count += 1\n",
        "#Do the parameter estimates vary a lot between the subjects or between the volleyball matches?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f29z5mXj2Xfx"
      },
      "outputs": [],
      "source": [
        "#Simulation best model structure\n",
        "number_a=5\n",
        "number_b=5\n",
        "d=5\n",
        "\n",
        "data = pd.concat([M_334_df['u_C6'].rename(\"u\"), M_334_df['y_C6'].rename(\"y\")], axis=1)\n",
        "# print the relative dataframe and check its columns\n",
        "y_loader, y_auto, parameters_a, parameters_b, SSG, tau, r_squared, aic, Rmse, bic, fpe = model_generator(data, number_a, number_b, d)\n",
        "\n",
        "\n",
        "#Ploting\n",
        "plt.figure(figsize=(20, 6))\n",
        "X_axis = np.arange(0,y_loader.shape[0])\n",
        "print(X_axis)\n",
        "# Plot the actual values (y_loader)\n",
        "plt.plot(data['y'], label='Real Value (y_loader)', color='blue')\n",
        "plt.plot(data['u'], label='Real Input (y_loader)', color='purple', linestyle=':')\n",
        "# Plot the original data (y)    *AUTOMATIC\n",
        "plt.plot(X_axis, y_auto, label='Predicted Automatic (y_auto)', color='red', linestyle='--')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Time / Index')\n",
        "plt.ylabel('Values')\n",
        "plt.title('Comparison of Real data (y_loader) and Model Prediction (y_auto)')\n",
        "plt.legend()  # Add a legend\n",
        "plt.grid(True) # Add grid lines for better readability\n",
        "# Adjust the y-axis limits if necessary for better visualization\n",
        "#plt.ylim([50, 200])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFsxxpIWUDxM"
      },
      "source": [
        "# Decompose ARX Modell\n",
        "Every higher order system can be described as a combination of several first order systems.\n",
        "* Serial coupling\n",
        "* Parallel coupling\n",
        "* Feedback coupling\n",
        "\n",
        "\n",
        "\n",
        "How to find model:\n",
        "1. Reducing the model order by polynomial division (only when m>n)\n",
        "2. Decomposition into first order models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqQajxc99wDK"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNT6auz1SSCd"
      },
      "outputs": [],
      "source": [
        "import control as ctrl\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def draw_tf_scheme(tf_type, tf1, tf2, tf3):\n",
        "    \"\"\"Draws a scheme of the transfer functions using networkx,\n",
        "    including TF3 in parallel, with nodes in a linear layout.\"\"\"\n",
        "\n",
        "    graph = nx.DiGraph()\n",
        "    graph.add_node(\"Input\", layer=0)\n",
        "    graph.add_node(\"Output\", layer=2)  # Output layer is now 2\n",
        "\n",
        "    # Add TF3 in parallel\n",
        "    graph.add_node(\"TF3\", layer=1)\n",
        "    graph.add_edges_from([(\"Input\", \"TF3\"), (\"TF3\", \"Output\")])\n",
        "\n",
        "    if tf_type == \"Series\":\n",
        "        graph.add_node(\"TF1\", layer=0)\n",
        "        graph.add_node(\"TF2\", layer=1)\n",
        "        graph.add_edges_from([(\"Input\", \"TF1\"), (\"TF1\", \"TF2\"), (\"TF2\", \"Output\")])\n",
        "        pos = nx.multipartite_layout(graph, subset_key=\"layer\")\n",
        "        plt.title(f\"Series Configuration: ({tf1} -> {tf2}) || {tf3}\")\n",
        "\n",
        "    elif tf_type == \"Parallel\":\n",
        "        graph.add_node(\"TF1\", layer=1)\n",
        "        graph.add_node(\"TF2\", layer=1)\n",
        "        graph.add_edges_from([(\"Input\", \"TF1\"), (\"Input\", \"TF2\"), (\"TF1\", \"Output\"), (\"TF2\", \"Output\")])\n",
        "        pos = nx.multipartite_layout(graph, subset_key=\"layer\")\n",
        "        plt.title(f\"Parallel Configuration: ({tf1} || {tf2}) || {tf3}\")\n",
        "\n",
        "    elif tf_type == \"Feedback\":\n",
        "        graph.add_node(\"TF1\", layer=1)\n",
        "        graph.add_node(\"TF2\", layer=1)\n",
        "        graph.add_edges_from([(\"Input\", \"TF1\"), (\"TF1\", \"Output\"), (\"Output\", \"TF2\"), (\"TF2\", \"TF1\")])\n",
        "        pos = nx.multipartite_layout(graph, subset_key=\"layer\")\n",
        "        plt.title(f\"Feedback Configuration: ({tf1} <-> {tf2}) || {tf3}\")\n",
        "\n",
        "    # Draw the graph\n",
        "    nx.draw(graph, with_labels=True, node_color=\"skyblue\", node_size=1500, pos=pos)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SEb1_cZ2XV7"
      },
      "outputs": [],
      "source": [
        "\n",
        "def decomposition_model(params_a, params_b): #params_a = den = n  ;   params_b = num = m\n",
        "  result = {}\n",
        "  m = len(params_b)\n",
        "  n = len(params_a)-1\n",
        "  #print(params_a,params_b)\n",
        "  #coefficients of the polynomials in decreasing powers\n",
        "  par_a = np.poly1d(np.flip(params_a))\n",
        "  par_b = np.poly1d(np.flip(params_b))\n",
        "  #print(par_a,par_b)\n",
        "\n",
        "  #Step 1  -  Polynomial Division\n",
        "  if m >= n:\n",
        "    quotient, remainder = np.polydiv(par_b, par_a)\n",
        "    #quotient,remainder = deconvolve(par_b,par_a)\n",
        "    print(f'Remainder:{remainder}  Quotient:{quotient}')\n",
        "    params_c = remainder\n",
        "  else:\n",
        "    params_c = par_b\n",
        "    quotient = []\n",
        "  #Q and C are in parallel\n",
        "  #print(\"C:\", params_c, \"C_0=\", params_c[0])\n",
        "  #print(f'Order a:{len(params_a)}  b:{len(params_a)} c:{len(params_c)} Q:{len(quotient)}\\n\\n')\n",
        "\n",
        "  #Step 2 - Decomposition\n",
        "  #2.a - All possible configurations:\n",
        "  decompositions = {}\n",
        "  A1 = params_a[-2]\n",
        "  A2 = params_a[-1]\n",
        "  B0 = params_c[0]\n",
        "  B1 = params_c[1]\n",
        "  print(f'B0:{B0} B1:{B1} A1:{A1} A2:{A2}')\n",
        "\n",
        "\n",
        "  #Configurations\n",
        "  #Series\n",
        "  s_b1, s_b2, s_a1, s_a2 = serial(B0,B1,A1,A2)\n",
        "  #Parallel\n",
        "  p_b1, p_b2, p_a1, p_a2 = parallel(B0,B1,A1,A2)\n",
        "  #Feedback\n",
        "  #fr_b1, fr_b2, fr_a1, fr_a2 = reverse_set3(B0,B1,A1,A2)\n",
        "  fr_b1, fr_b2, fr_a1, fr_a2 = feedback_m(B0,B1,A1,A2)\n",
        "  f_b1, f_b2, f_a1, f_a2 = feedback(B0,B1,A1,A2)\n",
        "  fr2_b1, fr2_b2, fr2_a1, fr2_a2 = reverse_set31(B0,B1,A1,A2)\n",
        "  configurations = { 'Series': {'b1': s_b1, 'b2': s_b2, 'a1': s_a1, 'a2': s_a2},\n",
        "                    'Parallel': {'b1': p_b1, 'b2': p_b2, 'a1': p_a1, 'a2': p_a2},\n",
        "                    'Feedback': {'b1': f_b1, 'b2': f_b2, 'a1': f_a1, 'a2': f_a2}}\n",
        "  #2.b - Remove Imaginary Values\n",
        "  #print(\"Configuration Inicial:\", configurations)\n",
        "\n",
        "  #Step 3 - Remove unstable configurations\n",
        "  #if |a| > 1 ---> 1-a < 0 ---> TC < 0 (not real meaning)\n",
        "  for types in configurations: #'Series', 'Parallel', 'Feedback'\n",
        "    unstable_configurations = False\n",
        "    #print(\"Checking unstable configuration from: {}\",types)\n",
        "\n",
        "    for param in configurations[types]: #'b1','b2','a1','a2'\n",
        "      if param.startswith('a'): #or configurations[types][param] == 'a2':\n",
        "        #check if \"a\" > 1 and save the configuration if not\n",
        "        if abs(configurations[types][param]) > 1 or isinstance(configurations[types][param], complex): #second part is for complex numbers\n",
        "          unstable_configurations = True #mark configuration as \"impossible\"\n",
        "\n",
        "    if unstable_configurations:\n",
        "      configurations[types] = {}\n",
        "      #result.update({f\"{r_types}\" : {'TF_1':TF_1,'TF_2':TF_2,'TC_1':TC_1,'TC_2':TC_2, 'G1':K1, 'G2':K2}})\n",
        "    print(f'Final result: {configurations}\\n')\n",
        "\n",
        "\n",
        "  #Probable real configurations\n",
        "  for r_types in configurations:\n",
        "    if configurations[r_types] == {}:\n",
        "      result.update({f\"{r_types}\" : {'Unstable'}})\n",
        "      continue\n",
        "    #Initialize var\n",
        "    pre_TF_1 = []\n",
        "    pre_TF_2 = []\n",
        "    TF_r = None\n",
        "    #define the TFs\n",
        "    for param in configurations[r_types]:\n",
        "      if param.endswith('1'):\n",
        "        pre_TF_1.append(configurations[r_types][param]) #(b1,a1)\n",
        "      elif param.endswith('2'):\n",
        "        pre_TF_2.append(configurations[r_types][param]) #(b2, a2)\n",
        "      else:\n",
        "        print(\"Unkown situation for:\",param,\"in\",r_types)\n",
        "    pre_TF_1.append(1)\n",
        "    pre_TF_2.append(1)\n",
        "    TF_1 = ctrl.TransferFunction(pre_TF_1[0], pre_TF_1[1:][::-1])\n",
        "    TF_2 = ctrl.TransferFunction(pre_TF_2[0], pre_TF_2[1:][::-1])\n",
        "    print(f\"Une: {r_types}\\n TF1: {TF_1} TF2: {TF_2}\")\n",
        "\n",
        "\n",
        "    #Step 4\n",
        "    #1 - Time Constants and Gain\n",
        "    poles1 = ctrl.poles(TF_1)\n",
        "    TC_1 = -1 / poles1\n",
        "    K1 = ctrl.dcgain(TF_1) # Method 2: Using dcgain ??? DCgain = -SSG?\n",
        "    poles2 = ctrl.poles(TF_2)\n",
        "    TC_2 = -1 / poles2\n",
        "    K2 = ctrl.dcgain(TF_2) # Method 2: Using dcgain ??? DCgain = -SSG?\n",
        "\n",
        "    result.update({f\"{r_types}\" : {'TF_1':TF_1,'TF_2':TF_2,'TC_1':TC_1,'TC_2':TC_2, 'G1':K1, 'G2':K2}})\n",
        "\n",
        "\n",
        "\n",
        "    #Flowchart Representation\n",
        "    draw_tf_scheme(r_types, TF_1, TF_2, ctrl.tf(quotient.c,1))\n",
        "\n",
        "  return result\n",
        "    #Put the two configurations together\n",
        "'''    if r_types == 'Serial':\n",
        "      TF_r = ctrl.series(TF_1,TF_2)\n",
        "    elif r_types == 'Parallel':\n",
        "      TF_r = ctrl.parallel(TF_1,TF_2)\n",
        "    elif r_types == 'Feedback':\n",
        "      TF_r = ctrl.feedback(TF_1,TF_2)\n",
        "    print(f\"{r_types} conformation: {TF_r}\")'''\n",
        "\n",
        "    #2 - chronology\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#if quotient == []:\n",
        "#      print(\"No quotient\")\n",
        "\n",
        "  #den1 =  np.insert(-parameters_a, 0, 1)\n",
        "  #den = [1] + (-parameters_a).tolist() #a [1,a2,a3,...] (endogenous)\n",
        "  #TF = ctrl.TransferFunction(num, den)    #define transfer function\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #Step 4\n",
        "\n",
        "for index, model in best_models_df.iterrows():\n",
        "  A = model.loc['Parameters_a']\n",
        "  B = model.loc['Parameters_b']\n",
        "  print(f'\\n\\nModel: {model.loc[\"Code_Name\"]} \\nParameter \"A\": {A}\\nParameters \"B\": {B}')\n",
        "\n",
        "  print(decomposition_model(A,B))\n",
        "\n",
        "p_b = np.array([0.0007, -0.0008])\n",
        "p_a = np.array([1,-1.51104, 0.57089])\n",
        "decomposition_model(p_a,p_b) # Q = [0.0004, 0.033798] || R = [0.0007, -0.0008]\n",
        "'''\n",
        "p_b = np.array([2,1]) # x +2\n",
        "p_a = np.array([4,5,9,4]) #4x³+5x²+9x+4\n",
        "decomposition_model(p_a,p_b) # Q = [4,1,3] || R = [-2]\n",
        "\n",
        "#A(x) = 2x3 + 4x2 – 6x + 8 and B(x) = x2 + 3\n",
        "\n",
        "p_b = np.array([2,4,-6,8])\n",
        "p_a = np.array([1,0,3])\n",
        "decomposition_model(p_a,p_b) # Q = [2,-2] || R = [0, 8]'''\n",
        "\n",
        "\n",
        "p_b = np.array([0.6,0.3,0.54])\n",
        "p_a = np.array([-0.56,-0.33])\n",
        "result = decomposition_model(p_a,p_b)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulJI7B_dzcY9"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import cmath\n",
        "\n",
        "# Reverse function for Set 1\n",
        "def serial(b_0,b_1, a_1, a_2): # Only considers 1 value for \"B\"\n",
        "    # b'_{0-1} and b'_{0-2} can be any pair of numbers that multiply to b_0.\n",
        "    #b_0_1 = math.sqrt(b_0)  # Assume a symmetric solution for simplicity\n",
        "    b_0_1 = b_0 / 0.5\n",
        "    b_0_2 = b_0 / b_0_1\n",
        "\n",
        "    # Solve the quadratic equation for a'_{1-1} and a'_{1-2}\n",
        "    discriminant = a_1**2 - 4 * a_2\n",
        "    if discriminant < 0:\n",
        "        print(\"Serial: No real solution exists for a_1 and a_2. Mathematically unfeasible Conformation.\")\n",
        "        a_1_1 = (a_1 + cmath.sqrt(discriminant)) / 2\n",
        "        a_1_2 = (a_1 - cmath.sqrt(discriminant)) / 2\n",
        "        return b_0_1, b_0_2, a_1_1, a_1_2\n",
        "        #raise ValueError(\"No real solution exists for a_1 and a_2.\")\n",
        "\n",
        "    a_1_1 = (a_1 + math.sqrt(discriminant)) / 2\n",
        "    a_1_2 = (a_1 - math.sqrt(discriminant)) / 2\n",
        "\n",
        "    return b_0_1, b_0_2, a_1_1, a_1_2\n",
        "\n",
        "# Reverse function for Set 2\n",
        "def parallel(b_0, b_1, a_1, a_2):\n",
        "    # Solve for a'_{1-1} and a'_{1-2} using the quadratic equation\n",
        "    discriminant = a_1**2 - 4 * a_2\n",
        "    if discriminant < 0:\n",
        "        print(\"Parallel: No real solution exists for a_1 and a_2. Mathematically unfeasible Conformation.\")\n",
        "        a_1_1 = (a_1 + cmath.sqrt(discriminant)) / 2\n",
        "        a_1_2 = (a_1 - cmath.sqrt(discriminant)) / 2\n",
        "        #return -1\n",
        "        #raise ValueError(\"No real solution exists for a_1 and a_2.\")\n",
        "    else:\n",
        "      a_1_1 = (a_1 + math.sqrt(discriminant)) / 2\n",
        "      a_1_2 = (a_1 - math.sqrt(discriminant)) / 2\n",
        "\n",
        "\n",
        "    # Solve for b'_{0-2}\n",
        "    if a_1_1 != a_1_2:  # Prevent division by zero\n",
        "        print(a_1_1, a_1_2)\n",
        "        b_0_2 = (b_1 - b_0 * a_1_2) / (a_1_1 - a_1_2)\n",
        "    else:\n",
        "        raise ValueError(\"a'_{1-1} and a'_{1-2} are equal, division by zero.\")\n",
        "\n",
        "    # Solve for b'_{0-1}\n",
        "    b_0_1 = b_0 - b_0_2\n",
        "\n",
        "    return b_0_1, b_0_2, a_1_1, a_1_2\n",
        "\n",
        "# Reverse function for Set 3\n",
        "def feedback(b_0, b_1, a_1, a_2):\n",
        "    # Solve for the denominator (d)\n",
        "    if b_1 != 0:\n",
        "        d = b_0 / b_1\n",
        "    else:\n",
        "        d = 1 + b_0\n",
        "\n",
        "    # Solve for b'_{0-1} and b'_{0-2}\n",
        "    b_0_1 = b_0 * d\n",
        "    if b_0_1 != 0:\n",
        "        b_0_2 = (d - 1) / b_0_1\n",
        "    else:\n",
        "        b_0_2 = 0\n",
        "\n",
        "    # Solve the quadratic equation for a'_{1-1} and a'_{1-2}\n",
        "    discriminant = (a_1 * d)**2 - 4 * a_2 * d\n",
        "    if discriminant < 0:\n",
        "      print(\"Feedback: No real solution exists for a_1 and a_2. Mathematically unfeasible Conformation.\")\n",
        "      a_1_1 = (a_1 * d + cmath.sqrt(discriminant)) / 2\n",
        "      a_1_2 = (a_1 * d - cmath.sqrt(discriminant)) / 2\n",
        "      #raise ValueError(\"No real solution exists for a_1 and a_2.\")\n",
        "      #return -1\n",
        "    else:\n",
        "      a_1_1 = (a_1 * d + math.sqrt(discriminant)) / 2\n",
        "      a_1_2 = (a_1 * d - math.sqrt(discriminant)) / 2\n",
        "\n",
        "    return b_0_1, b_0_2, a_1_1, a_1_2\n",
        "\n",
        "def feedback_m(b_0, b_1, a_1, a_2):\n",
        "  a_1_2 = b_1 / b_0\n",
        "  a_1_1 = (a_2*a_1_2) / (a_1*a_1_2 - a_2)\n",
        "\n",
        "  d = (a_1_1 + a_1_2)/a_1\n",
        "\n",
        "  b_0_1 = (a_1_1*a_1_2*b_0) / a_2\n",
        "  b_0_2 = (((b_0_1 / b_0)-1)/b_0_1)\n",
        "  b_0_2 = (a_2/b_1) - (1/b_0_1)\n",
        "  return b_0_1, b_0_2, a_1_1, a_1_2\n",
        "\n",
        "def reverse_set3(b_0, b_1, a_1, a_2):\n",
        "    # Iteratively solve for b'_{0-2}\n",
        "    def solve_b_0_2():\n",
        "        # Start with an initial guess for b'_{0-2}\n",
        "        #b_0_2 = -0.5\n",
        "        for b_0_2 in [-0.5,2]:\n",
        "          for _ in range(100):  # Iterate to refine the solution\n",
        "              b_0_1 = b_0 / (1 - b_0 * b_0_2) if (1 - b_0 * b_0_2) != 0 else 0\n",
        "              if b_0_1 == 0:\n",
        "                  break\n",
        "              denominator = 1 + b_0_1 * b_0_2\n",
        "              a_1_1 = (a_1 * denominator + cmath.sqrt((a_1 * denominator)**2 - 4 * a_2 * denominator)) / 2\n",
        "              a_1_2 = (a_1 * denominator - cmath.sqrt((a_1 * denominator)**2 - 4 * a_2 * denominator)) / 2\n",
        "              predicted_b_1 = (b_0_1 * a_1_2) / denominator\n",
        "\n",
        "              if abs(predicted_b_1 - b_1) < 1e-1:  # Converged\n",
        "                  print(\"found\")\n",
        "                  return b_0_1, b_0_2, a_1_1, a_1_2\n",
        "              b_0_2 *= 0.95  # Adjust guess slightly\n",
        "          #return -1\n",
        "          raise ValueError(\"Failed to converge on a solution for b'_{0-2}.\")\n",
        "\n",
        "    # Solve for b'_{0-2}, b'_{0-1}, a'_{1-1}, a'_{1-2}\n",
        "    b_0_1, b_0_2, a_1_1, a_1_2 = solve_b_0_2()\n",
        "    #solve_b_0_2()\n",
        "    return b_0_1, b_0_2, a_1_1, a_1_2\n",
        "\n",
        "def reverse_set31(b_0, b_1, a_1, a_2):\n",
        "    # Step 1: Calculate z (b'_{0-1} * b'_{0-2})\n",
        "    z = (1 / b_0) - 1\n",
        "\n",
        "    # Step 2: Solve for a'_{1-1} and a'_{1-2}\n",
        "    sum_a = a_1 * (1 + z)  # a'_{1-1} + a'_{1-2}\n",
        "    prod_a = a_2 * (1 + z)  # a'_{1-1} * a'_{1-2}\n",
        "\n",
        "    discriminant_a = sum_a**2 - 4 * prod_a\n",
        "    if discriminant_a < 0:\n",
        "        print(\"Feedback2: No real solution exists for a_1 and a_2. Mathematically unfeasible Conformation.\")\n",
        "        a_1_1 = (sum_a + cmath.sqrt(discriminant_a)) / 2\n",
        "        a_1_2 = (sum_a - cmath.sqrt(discriminant_a)) / 2\n",
        "        #raise ValueError(\"No real solution for a'_{1-1} and a'_{1-2}.\")\n",
        "        #return -1\n",
        "    else:\n",
        "      a_1_1 = (sum_a + math.sqrt(discriminant_a)) / 2\n",
        "      a_1_2 = (sum_a - math.sqrt(discriminant_a)) / 2\n",
        "\n",
        "    # Step 3: Solve for b'_{0-1}\n",
        "    b_0_1 = (b_1 * (1 + z)) / a_1_2\n",
        "\n",
        "    # Step 4: Solve for b'_{0-2}\n",
        "    b_0_2 = z / b_0_1\n",
        "\n",
        "    return b_0_1, b_0_2, a_1_1, a_1_2         #-B1,B2 and A1 >=> A2\n",
        "#B0= 0.0007 B1= -0.0008, A1= -1.511, A2= 0.5708   ===>    b_1= -0.5393,  b_2= 0.54,  a_1= -0.7558,  a_2= -0.7552\n",
        "print(serial(0.002375307035356264,-0.002295340647311899 ,1, -1.511))\n",
        "print(parallel(0.002375307035356264,-0.002295340647311899 ,1, -1.511))\n",
        "print(reverse_set3(0.002375307035356264,-0.002295340647311899 ,1, -1.511))\n",
        "\n",
        "print(reverse_set31(0.002375307035356264,-0.002295340647311899 ,1, -1.511))\n",
        "print(feedback(0.002375307035356264,-0.002295340647311899 ,1, -1.511))\n",
        "print(feedback_m(0.002375307035356264,-0.002295340647311899 ,1, -1.511))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_zewf5KuUqo"
      },
      "outputs": [],
      "source": [
        "# Test input values\n",
        "b_0_1 = 0.002372\n",
        "b_0_2 = -0.5\n",
        "a_1_1 = 1.82553\n",
        "a_1_2 = -0.82672\n",
        "\n",
        "# Define the functions for the three sets\n",
        "def set1(b_0_1, b_0_2, a_1_1, a_1_2): #Serial\n",
        "    b_0 = b_0_1 * b_0_2\n",
        "    b_1 = 0\n",
        "    a_1 = a_1_1 + a_1_2\n",
        "    a_2 = a_1_1 * a_1_2\n",
        "    return b_0, b_1, a_1, a_2\n",
        "\n",
        "def set2(b_0_1, b_0_2, a_1_1, a_1_2):#Parallel\n",
        "    b_0 = b_0_1 + b_0_2\n",
        "    b_1 = b_0_1 * a_1_2 + b_0_2 * a_1_1\n",
        "    a_1 = a_1_1 + a_1_2\n",
        "    a_2 = a_1_1 * a_1_2\n",
        "    return b_0, b_1, a_1, a_2\n",
        "\n",
        "def set3(b_0_1, b_0_2, a_1_1, a_1_2):#Feedback\n",
        "    denominator = 1 + b_0_1 * b_0_2\n",
        "    b_0 = b_0_1 / denominator\n",
        "    b_1 = (b_0_1 * a_1_2) / denominator\n",
        "    a_1 = (a_1_1 + a_1_2) / denominator\n",
        "    a_2 = (a_1_1 * a_1_2) / denominator\n",
        "    return b_0, b_1, a_1, a_2\n",
        "\n",
        "# Calculate results for the test values\n",
        "result_set33 = set3(0.0004072344486155723, 0.0331, -0.0501, 0.0185)\n",
        "result_set1 = set1(b_0_1, b_0_2, a_1_1, a_1_2)\n",
        "result_set2 = set2(b_0_1, b_0_2, a_1_1, a_1_2)\n",
        "result_set3 = set3(b_0_1, b_0_2, a_1_1, a_1_2)\n",
        "print(\"Set 1:\", result_set1)\n",
        "print(\"Set 2:\", result_set2)\n",
        "print(\"Set 3:\", result_set3)\n",
        "print(\"Personal:\", result_set33)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9fFGY5IKRSx"
      },
      "outputs": [],
      "source": [
        "# Test output values\n",
        "b_0_1 = -0.5393\n",
        "b_0_2 = 0.54\n",
        "a_1_1 = -0.7558\n",
        "a_1_2 = -0.7552\n",
        "\n",
        "tolerance=1e-3\n",
        "\n",
        "#Calculate Inputs\n",
        "result_set1 = set1(b_0_1, b_0_2, a_1_1, a_1_2)\n",
        "result_set2 = set2(b_0_1, b_0_2, a_1_1, a_1_2)\n",
        "result_set3 = set3(b_0_1, b_0_2, a_1_1, a_1_2)\n",
        "\n",
        "\n",
        "#Verify if f(input) = output\n",
        "b_0, b_1, a_1, a_2 = result_set1\n",
        "s_b1, s_b2, s_a1, s_a2 = serial(b_0, b_1, a_1, a_2)\n",
        "if (b_0_1, b_0_2, a_1_1, a_1_2) == (s_b1, s_b2, s_a1, s_a2):\n",
        "  print(\"TRUEEEE S\")\n",
        "else:\n",
        "  print(\"Series: \",s_b1, s_b2, s_a1, s_a2)\n",
        "\n",
        "b_0, b_1, a_1, a_2 = result_set2\n",
        "p_b1, p_b2, p_a1, p_a2 = parallel(b_0, b_1, a_1, a_2)\n",
        "\n",
        "if all(np.isclose(v1, v2, atol=tolerance) for v1, v2 in zip([-b_0_1, -b_0_2, a_1_1, a_1_2], [p_b1, p_b2, p_a1, p_a2])):\n",
        "  print(\"Values are CLOSE\")\n",
        "\n",
        "if (b_0_1, b_0_2, a_1_1, a_1_2) == (p_b1, p_b2, p_a1, p_a2):\n",
        "  print(\"TRUEEEE P\")\n",
        "else:\n",
        "  print(\"Parallel: \",p_b1, p_b2, p_a1, p_a2, \"Result\",b_0_1, b_0_2, a_1_1, a_1_2)\n",
        "\n",
        "\n",
        "b_0, b_1, a_1, a_2 = result_set3\n",
        "fr_b1, fr_b2, fr_a1, fr_a2 = feedback_m(b_0, b_1, a_1, a_2)\n",
        "f_b1, f_b2, f_a1, f_a2 = feedback(b_0, b_1, a_1, a_2)\n",
        "fr2_b1, fr2_b2, fr2_a1, fr2_a2 = reverse_set31(b_0, b_1, a_1, a_2)\n",
        "\n",
        "if (b_0_1, b_0_2, a_1_1, a_1_2) == (f_b1, f_b2, f_a1, f_a2):\n",
        "  print(\"Feedback1\")\n",
        "else:\n",
        "  print(\"Feedback1: \",f_b1, f_b2, f_a1, f_a2)\n",
        "\n",
        "if (b_0_1, b_0_2, a_1_1, a_1_2) == (fr_b1, fr_b2, fr_a1, fr_a2):\n",
        "  print(\"Feedback2\")\n",
        "else:\n",
        "  print(\"Feedback2: \",(fr_b1, fr_b2, fr_a1, fr_a2))\n",
        "\n",
        "if (b_0_1, b_0_2, a_1_1, a_1_2) == (fr2_b1, fr2_b2, fr2_a1, fr2_a2):\n",
        "  print(\"Feedbackr2\")\n",
        "else:\n",
        "  print(\"Feedbackr2: \",fr2_b1, fr2_b2, fr2_a1, fr2_a2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmnGIJ7ZjwmP"
      },
      "outputs": [],
      "source": [
        "\n",
        "p_b = np.array([0.0007, -0.0008])\n",
        "p_a = np.array([1,-1.5110, 0.5708])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATGXKyVsVORb"
      },
      "outputs": [],
      "source": [
        "# Test Input values\n",
        "b_0 = 0.0007\n",
        "b_1 = -0.0008\n",
        "a_1 = -1.510\n",
        "a_2 = 0.570\n",
        "\n",
        "# Calculate Outputs\n",
        "\n",
        "s_b1, s_b2, s_a1, s_a2 = serial(b_0, b_1, a_1, a_2)\n",
        "result_set1 = set1(s_b1, s_b2, s_a1, s_a2)\n",
        "if (b_0, b_1, a_1, a_2) == result_set1:\n",
        "  print(f\"Equal Serie: {result_set1}\")\n",
        "else:\n",
        "  print(\"Series: \",result_set1)\n",
        "\n",
        "p_b1, p_b2, p_a1, p_a2 = parallel(b_0, b_1, a_1, a_2)\n",
        "result_set2 = set2(p_b1, p_b2, p_a1, p_a2)\n",
        "if (b_0, b_1, a_1, a_2) == result_set2:\n",
        "  print(f\"\\nEqual Parallel: {result_set2}\\n{p_b1, p_b2, p_a1, p_a2}\\n\")\n",
        "else:\n",
        "  print(\"Parallel: \",result_set2,p_b1, p_b2, p_a1, p_a2,\"\\n\\n\")\n",
        "\n",
        "\n",
        "fr_b1, fr_b2, fr_a1, fr_a2 = feedback_m(b_0, b_1, a_1, a_2)\n",
        "result_set3 = set3(fr_b1, fr_b2, fr_a1, fr_a2)\n",
        "if (b_0, b_1, a_1, a_2) == result_set3:\n",
        "  print(f\"\\nEqual Feedback(mine): {result_set3}\\n\")\n",
        "else:\n",
        "  print(\"Feedback(mine): \",result_set3)\n",
        "\n",
        "f_b1, f_b2, f_a1, f_a2 = feedback(b_0, b_1, a_1, a_2)\n",
        "result_set3 = set3(f_b1, f_b2, f_a1, f_a2)\n",
        "if (b_0, b_1, a_1, a_2) == result_set3:\n",
        "  print(f\"Equal Feedback(norm): {result_set3}\")\n",
        "else:\n",
        "  print(\"Feedback(norm): \",result_set3)\n",
        "\n",
        "fr2_b1, fr2_b2, fr2_a1, fr2_a2 = reverse_set31(b_0, b_1, a_1, a_2)\n",
        "result_set3 = set3(fr2_b1, fr2_b2, fr2_a1, fr2_a2)\n",
        "if (b_0, b_1, a_1, a_2) == result_set3:\n",
        "  print(f\"Equal Feedback(31): {result_set3}\")\n",
        "else:\n",
        "  print(\"Feedback(31): \",result_set3)\n",
        "\n",
        "try:\n",
        "  fr1_b1, fr1_b2, fr1_a1, fr1_a2 = reverse_set3(b_0, b_1, a_1, a_2)\n",
        "  result_set3 = set3(fr1_b1, fr1_b2, fr1_a1, fr1_a2)\n",
        "except:\n",
        "  print(\"No solution\")\n",
        "finally:\n",
        "  if (b_0, b_1, a_1, a_2) == result_set3:\n",
        "    print(f\"Equal Feedback(iter): {result_set3}\")\n",
        "  else:\n",
        "      print(\"Feedback(iter): \",result_set3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaX7XoMhbJBe"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "def draw_coupling_diagram(coupling_type, poles, residues):\n",
        "    \"\"\"\n",
        "    Visualize the system as a block diagram for a given coupling type.\n",
        "\n",
        "    Parameters:\n",
        "    - coupling_type: str (\"series\", \"parallel\", or \"feedback\")\n",
        "    - poles: List of poles\n",
        "    - residues: List of residues\n",
        "    \"\"\"\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Nodes for each subsystem\n",
        "    for i, (p, r) in enumerate(zip(poles, residues), 1):\n",
        "        G.add_node(f\"Subsystem {i}\\nPole: {p:.2f}\\nResidue: {r:.2f}\")\n",
        "\n",
        "    # Define connections based on coupling type\n",
        "    if coupling_type == \"series\":\n",
        "        edges = [(f\"Subsystem {i}\", f\"Subsystem {i+1}\") for i in range(1, len(poles))]\n",
        "    elif coupling_type == \"parallel\":\n",
        "        edges = [(\"Input\", f\"Subsystem {i}\") for i in range(1, len(poles) + 1)]\n",
        "        edges += [(f\"Subsystem {i}\", \"Output\") for i in range(1, len(poles) + 1)]\n",
        "        G.add_node(\"Input\")\n",
        "        G.add_node(\"Output\")\n",
        "    elif coupling_type == \"feedback\":\n",
        "        edges = [(\"Input\", \"Subsystem 1\")]\n",
        "        edges += [(f\"Subsystem {i}\", f\"Subsystem {i+1}\") for i in range(1, len(poles))]\n",
        "        edges += [(f\"Subsystem {len(poles)}\", \"Input\")]\n",
        "\n",
        "    # Add edges\n",
        "    G.add_edges_from(edges)\n",
        "\n",
        "    # Draw the graph\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    pos = nx.spring_layout(G) if coupling_type != \"parallel\" else nx.shell_layout(G)\n",
        "    nx.draw(\n",
        "        G,\n",
        "        pos,\n",
        "        with_labels=True,\n",
        "        node_size=3000,\n",
        "        node_color=\"lightblue\",\n",
        "        font_size=10,\n",
        "        font_weight=\"bold\",\n",
        "        edge_color=\"gray\",\n",
        "    )\n",
        "    plt.title(f\"{coupling_type.capitalize()} Coupling Diagram\", fontsize=14)\n",
        "    plt.show()\n",
        "\n",
        "# Example poles and residues (replace with real values from decomposition)\n",
        "poles = [-1, -2, -3]\n",
        "residues = [0.5, 0.3, 0.2]\n",
        "\n",
        "# Visualize each coupling type\n",
        "draw_coupling_diagram(\"series\", poles, residues)\n",
        "draw_coupling_diagram(\"parallel\", poles, residues)\n",
        "draw_coupling_diagram(\"feedback\", poles, residues)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHFC309qUC2p"
      },
      "outputs": [],
      "source": [
        "#Using NumPy’s polydiv Function\n",
        "A = [2, 4, -6, 8]\n",
        "B = [1, 0, 3]\n",
        "\n",
        "quotient, remainder = np.polydiv(A, B)\n",
        "\n",
        "print(f\"\\nUsing NumPy’s polydiv Function\\nQuotient: {quotient}\\nRemainder: {remainder}\\n\")\n",
        "\n",
        "#Using SymPy’s div Function\n",
        "from sympy import symbols, div\n",
        "x = symbols('x')\n",
        "A = 2*x**3 + 4*x**2 - 6*x + 8\n",
        "B = x**2 + 3\n",
        "\n",
        "quotient, remainder = div(A, B, domain='QQ')\n",
        "\n",
        "print(f\"\\nUsing SymPy’s div Function\\nQuotient: {quotient}\\nRemainder: {remainder}\\n\")\n",
        "\n",
        "#Manual Polynomial Long Division\n",
        "def poly_long_div(dividend, divisor):\n",
        "    quotient = []\n",
        "    while len(dividend) >= len(divisor):\n",
        "        lead_coeff = dividend[0] / divisor[0]\n",
        "        quotient.append(lead_coeff)\n",
        "        dividend = [coeff - lead_coeff * div_coeff for coeff, div_coeff in zip(dividend, divisor + [0]*(len(dividend)-len(divisor)))]\n",
        "        dividend.pop(0)\n",
        "    return quotient, dividend\n",
        "\n",
        "A = [2, 4, -6, 8]\n",
        "B = [1, 0, 3]\n",
        "quotient, remainder = poly_long_div(A, B)\n",
        "print(f\"\\nManual Polynomial Long Division\\nQuotient: {quotient}\\nRemainder: {remainder}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVgmwMcqUCzk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laLWPSboUCwJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaOjvsegUCtL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fooHYgTUClh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lblg8wr5UCh1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40cq_aEpUCe6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFM9ZcXyUCcG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7tOmUCXUCZS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOz1ZrDgUCQb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUQjIxbibm-B"
      },
      "outputs": [],
      "source": [
        "def dataloader(data, na, nb, d):\n",
        "\n",
        "    # Initialize empty arrays for lagged features\n",
        "    u = data['u']\n",
        "    X = pd.DataFrame()\n",
        "    y = data['y']\n",
        "\n",
        "\n",
        "    # Create lagged features for input ('b' parameters)\n",
        "    for i in range(0,nb):\n",
        "        X['u-{}'.format(i + d)] = u.shift(i + d)\n",
        "    # Create lagged features for output ('a' parameters)\n",
        "    for i in range(1,na+1):\n",
        "        X['y-{}'.format(i)] = y.shift(i)\n",
        "\n",
        "\n",
        "    X = X.iloc[max(na,nb+d):]\n",
        "    # Set the target values\n",
        "    y = y[max(na,nb+d):]\n",
        "\n",
        "    X.reset_index(drop=True, inplace=True)\n",
        "    y.reset_index(drop=True, inplace=True)\n",
        "    return X, y"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}